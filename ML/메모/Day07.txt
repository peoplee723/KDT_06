Day07

Decision Tree (결정트리)
- 범주/수치형 데이터 모두 사용가능
	=>수치형인 경우 비교연산을 통해 분류(노드의 특성 평균값으로  분류)
- 질문(첫 질문=뿌리 노드 -> 2개분기(가지) ->질문(중간노드).... ->결정값(잎노드)
- ++분할속성(다음 질문 선정 기준)에 따라 복잡도가 달라짐!
- 	how? 가능한 많은 동일 분류의 데이터가 모이는 속성을 선택
트리의 복잡도를 조절-> max_depth(최대 깊이조절), min_sample_split(노드 최소 데이터 수)
H-parms=> min_samples_split,
장점
- 스케일링, 전처리 필요 없음!
단점
- 과대적합으로 성능이 저조함
혼자서는 저조한 성능-> 앙상블을 통해 성능 향상

Ensemble (앙상블)
모델 여러개 결합하여 정확도 올리는 학습방법 (오차(편향)방지)

모델 및 샘플 결합 방법에 따른 앙상블 분류(3개)
왜 Decision Tree? -> 가만히 놔누면 정확도 높음 but 과대적합 문제=> 앙상블 최적화
1. 보팅-> 서로 다른 알고리즘 같은 데이터 투표를 통해 최종 결과 결정
2. 배깅-> 서로 같은 알고리즘  중복허용한 샘플링 다르게 하면서 병렬 학습 수행  (ex. 랜덤 포레스트)
3. 페이스팅-> 서로 같은 알고리즘 중복불허한 샘플링 다르게 하면서 보팅 수행


