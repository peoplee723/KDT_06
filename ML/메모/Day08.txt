Day08

올바른 피쳐를 선택하는 방법??
- 시각화 (ex. 분류의 경우 타켓 기준으로 groupby후 시각화
1. dt의 importance_features_
2. linear 모델의 coef_

SimpleImputer-> 결측치 처리 방법 지정 가능! (수학적 방법 바탕으로)
KNNImputer-> 결측치 처리 가까이 있는 거로 대체

인코딩
label ->1D ==> target용

ordinal -> 2D ==> feature 용, 순서 의미 있을때
	 -> 데이터의 순서(인덱싱)을 바탕으로 매핑, 
==> label, ordinal 차이는 차원 차이
onehot -> 2D ==> feature용, 순서 의미 없을때


랜덤 포레스트
dt기반 알고리즘, 빠른속도, 높은성능
- 중복허용한 무작위 샘플링-> 학습 -> 투표(보팅) -> 최적 모델 선정
- 하이퍼 파라미터: 트리 하이퍼 파라미터 
			+n_estimators: 결정 트리 개수
++트리는 범주형 데이터 지원 안함

extraTree
dt기반 알고리즘, 매우 빠른 속도
- 중복 불허한 무작위 분할후 선택-> 학습

분류 모델 성능지표
정확도, 오차행렬(혼돈행렬), 정밀도, 재현율, f1스코어, roc auc
==>혼돈 행렬 (다중일 경우 one vs rest로 분류해서 계산)
		  예측	
		N	P
실제	N	TN	FP
	P	FN	TP

1. 정확도 = 정답/전체
		=>불균형 데이터의 경우 신뢰성 하락
2. 정밀도 = True정답 / True로 예측->  (TP/(FP+TP)

3. 재현율 = True정답 / 실제True->  TP/(FN+TP)

  ===>정밀도와 재현율은 임계값에 따라 바뀜
4. F1 Score = 2*(정밀도*재현율)/(정밀도+재현율) 

그래서 어떤 지표가 더 중요한가? -> 상황에 따라 다름

재현율이 더 중요=> 참을 거짓으로 판단할 때 큰 악영향 발생할 때
			ex) 암, 범죄자 판단
정밀도가 더 중요=> 거짓을 참으로 판단한 경우 큰 악영향 발생할 때
			ex)스팸 메일 판단


이때가지 배운 모델
KNN
linear -> 다중, 다항
		-> 과대적합 해결 위한 규제:alpha
		-> 릿지, 라쏘, 엘라스틱넷
	-> 로지스틱스 (선형식에 로그를 취해서 확률값으로 변환)
		->Ovr, Ova 2진 분류기를 여러개 =>x수만큼
		->OvO 2진 분류기를 여러개=> xC2
Tree  -> 회귀/분류-> scikit-learn에서는 수치형만
		하이퍼파라미터 많음
ensemble-> Voting, bagging(randomForest)

피쳐 선택법 -> 하나씩 추가하기 or 다넣고 하나씩 빼기


