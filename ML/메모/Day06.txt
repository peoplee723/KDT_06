Day06

선형모델
피쳐 회귀값(영향력) 조절-> 규제
릿지(0에 가깝게), 라쏘(0으로), 엘라스틱넷()


하이퍼 파라미터
-> alpha, K개수, max_iter(학습 횟수), C(알파의 역수)
튜닝
-> 하이퍼파라이터 조절하여 최적의 모델 찾기
=>스케일링과 학습모델, 교차검증까지 한번에 할 수 있도록 함수 만들기?

로지스틱스 회귀 (선형 회귀 방식을 분류에 적용한 알고리즘)
=>하이퍼파라미터: c, max_iter, penalty, soler, 
+ penalty 종류에 따른 가능한 solver 상이-> user guide 참조
이론-> 확률과 오즈와의 관계식을 logit으로 변환(계산하기 쉽게, 보기 쉽게)
범주형 데이터를 선형식으로 나타내기 위한 함수= 시그모이드 함수
pd.exp(1/1-p^e) 또는 scipy.expit(p)
ŷ : 예측값
삼중분류 이상일때 -> ex)합, 불합, 대기 => 합- 합외, 불합-불합 외, 대기-대기 외로 비율을 구함

OvR/OvA 분류
one vs rest(나머지)
각 하나씩 이진분류

OvO 분류
one vs one
분류의 조합의 수
(1,2,3,4,5) -> 5C2=5!/(2!*(5-2)!)-> 10
xC2= x!/(2!*(x-2)!-> x*(x-1)/2

predict-> 결과, 인덱스 출력

10c2= 10!/ 2!*8!= 90/2=45
