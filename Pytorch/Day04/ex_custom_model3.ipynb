{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사용자 정의 모델 클래스\n",
    "- 부모 클래스: nn.module\n",
    "- 필수 오버라이딩\n",
    "    - __init__(): 모델 구성 즉, 설계\n",
    "    - forward(): 순방향 학습 진행 코드 구현\n",
    "- 동적 모델\n",
    "    - container 모듈 중 nn.ModulList() 사용해서 동적으로 Layer 추가\n",
    "        - forward 기능 미 제공\n",
    "        - layer 인스턴스 요소 사이에 연관성 없음\n",
    "        - layer 인스턴스 요소는 인덱싱으로 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈로딩\n",
    "import torch                                            # 텐서 관련 모듈\n",
    "import torch.nn as nn                                   # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F                         # 인공신경망 관련 함수들 모듈(손실,활성화 함수)\n",
    "import torch.optim as optim                             # 최적화 관련 모듈(가중치, 절편 빠르게 찾아주는 알고리즘)\n",
    "from torchinfo import summary                           # 모델 구조 및 정보 관련 모듈\n",
    "from torchmetrics.regression import *                   # 회귀 성능 지표 관련 모듈\n",
    "from torchmetrics.classification import *               # 분류 성능 지표 관련 모듈\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [기본] 신경망클래스  <hr>\n",
    "    - 입력층 -> 입력: 피쳐수 고정\n",
    "    - 출력층 -> 출력: 타겟수 고정\n",
    "    - 은닉층 -> 고정\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 고정\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 텐서 저장 및 실행 위치 설정\n",
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 설계 - 동적 모델 <hr>\n",
    "    - 목표: 은닉층의 개수가 동적인 모델\n",
    "    - 조건\n",
    "        - 입력층과 출력층 개수 동적 => 입력층의 입력값, 출력층의 출력값\n",
    "        - 은닉층의 개수 동적 => 퍼셉트론 개수 고정 => 은닉층의 개수, 은닉층 마다 퍼셉트론 수 \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이름: DynamicModel\n",
    "# 부모클래스: nn.Module\n",
    "# 매개변수: in_in, out_out, h_ins=[], h_outs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicModel(nn.Module):\n",
    "    # 생성자 메서드\n",
    "    def __init__(self, in_in, out_out, in_out, h_ins=[], h_outs=[]) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_layer=nn.Linear(in_in, h_ins[0] if len(h_ins) else in_out)\n",
    "        self.h_layers=nn.ModuleList()\n",
    "        for idx in range(len(h_ins)):\n",
    "            self.h_layers.append(nn.Linear(h_ins[idx], h_outs[idx]))\n",
    "        self.out_layer=nn.Linear(h_outs[-1] if len(h_outs) else in_out, out_out)\n",
    "    # 학습 진행 콜백 메서드\n",
    "    def forward(self, x):\n",
    "        y=self.in_layer(x)\n",
    "        y=F.relu(y)\n",
    "        \n",
    "        for linear in self.h_layers:\n",
    "            y= linear(y)\n",
    "            y=F.relu(y)\n",
    "\n",
    "        return self.out_layer(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스 생성\n",
    "h_ins, h_outs=[30,50,70], [50,70,30]\n",
    "m1=DynamicModel(in_in=3, in_out=5, out_out=2, h_ins=h_ins, h_outs=h_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_layer.weight Parameter containing:\n",
      "tensor([[-0.3492,  0.0725,  0.5754],\n",
      "        [-0.3647,  0.3077, -0.3196],\n",
      "        [-0.5428, -0.1227,  0.3327],\n",
      "        [ 0.5360, -0.3586,  0.1253],\n",
      "        [ 0.4982,  0.3826,  0.3598],\n",
      "        [ 0.4103,  0.3652,  0.1491],\n",
      "        [-0.3948, -0.4848, -0.2646],\n",
      "        [-0.0672, -0.3539,  0.2112],\n",
      "        [ 0.1787, -0.1307,  0.2219],\n",
      "        [ 0.1866,  0.3525,  0.3888],\n",
      "        [-0.1955,  0.5641, -0.0667],\n",
      "        [-0.0198, -0.5449, -0.3716],\n",
      "        [-0.3373, -0.2469,  0.4105],\n",
      "        [-0.1887, -0.4314,  0.2221],\n",
      "        [ 0.1848,  0.3739, -0.2988],\n",
      "        [ 0.1252, -0.2102, -0.1297],\n",
      "        [-0.4601, -0.2631, -0.1768],\n",
      "        [ 0.2469,  0.1055,  0.1426],\n",
      "        [ 0.5763,  0.5627,  0.3938],\n",
      "        [ 0.0184, -0.3994,  0.4512],\n",
      "        [-0.1444, -0.0467, -0.4974],\n",
      "        [-0.1140, -0.3724,  0.5305],\n",
      "        [-0.4991, -0.4500, -0.0196],\n",
      "        [-0.3122,  0.2066, -0.2222],\n",
      "        [-0.2712,  0.0327,  0.4179],\n",
      "        [-0.4061,  0.2711,  0.3709],\n",
      "        [ 0.5648, -0.4041,  0.1398],\n",
      "        [-0.4269,  0.4929, -0.2240],\n",
      "        [ 0.3478,  0.0172, -0.0450],\n",
      "        [-0.0184,  0.0981,  0.2722]], requires_grad=True)\n",
      "in_layer.bias Parameter containing:\n",
      "tensor([ 0.0926,  0.1761, -0.5193,  0.4206,  0.5034,  0.4772,  0.4268, -0.4166,\n",
      "        -0.2140,  0.5091, -0.4397,  0.5238, -0.4541, -0.4067,  0.2823, -0.4148,\n",
      "        -0.1323,  0.4200,  0.4573,  0.5460, -0.1172, -0.4488,  0.5685, -0.1230,\n",
      "        -0.2375,  0.1407, -0.4038,  0.3795,  0.3618, -0.4581],\n",
      "       requires_grad=True)\n",
      "h_layers.0.weight Parameter containing:\n",
      "tensor([[-0.1500, -0.0160,  0.0767,  ..., -0.1363,  0.1687, -0.1174],\n",
      "        [ 0.0516,  0.0556,  0.0434,  ...,  0.0025, -0.1043, -0.1019],\n",
      "        [-0.0272, -0.0526,  0.0448,  ...,  0.0414, -0.1320, -0.0390],\n",
      "        ...,\n",
      "        [-0.1051,  0.0998,  0.1675,  ...,  0.1253, -0.0708, -0.0255],\n",
      "        [-0.0560,  0.0049,  0.0602,  ..., -0.0201, -0.0108,  0.0853],\n",
      "        [ 0.0229,  0.0350,  0.0966,  ..., -0.1825,  0.1040, -0.1624]],\n",
      "       requires_grad=True)\n",
      "h_layers.0.bias Parameter containing:\n",
      "tensor([ 0.0243, -0.1811, -0.1567,  0.1469, -0.1005, -0.0063,  0.0081,  0.1680,\n",
      "         0.0583,  0.0891, -0.0781, -0.0626,  0.1328,  0.0669,  0.0458, -0.1377,\n",
      "        -0.1457,  0.0369, -0.1370,  0.1280,  0.1521, -0.0756, -0.1177,  0.1767,\n",
      "        -0.0974, -0.1455, -0.1325,  0.0317,  0.0355,  0.1179,  0.1470,  0.0779,\n",
      "         0.0261,  0.1649, -0.0753, -0.0320,  0.1546, -0.0615,  0.0979,  0.0392,\n",
      "         0.0644, -0.0417, -0.1555,  0.1309,  0.1503, -0.1450, -0.0854,  0.0077,\n",
      "         0.0905, -0.0258], requires_grad=True)\n",
      "h_layers.1.weight Parameter containing:\n",
      "tensor([[-0.0620,  0.1101, -0.0710,  ...,  0.0642, -0.0553, -0.0772],\n",
      "        [ 0.0285, -0.1287,  0.0188,  ..., -0.0844, -0.1219, -0.0178],\n",
      "        [ 0.0144, -0.1137, -0.0520,  ...,  0.0288, -0.0485, -0.1165],\n",
      "        ...,\n",
      "        [ 0.0261, -0.0744, -0.0297,  ..., -0.0549,  0.1021,  0.0672],\n",
      "        [ 0.1031, -0.0223,  0.1281,  ...,  0.0976,  0.0617, -0.0613],\n",
      "        [-0.0009,  0.0138,  0.0026,  ...,  0.0776, -0.0389,  0.0978]],\n",
      "       requires_grad=True)\n",
      "h_layers.1.bias Parameter containing:\n",
      "tensor([ 1.3243e-01,  1.4030e-02,  3.9292e-02, -3.9978e-02, -1.0490e-02,\n",
      "        -6.7761e-03, -7.1646e-02,  2.4447e-02, -6.0313e-02,  7.2174e-02,\n",
      "         2.1709e-02, -1.0960e-01,  1.2688e-01,  4.2307e-02,  6.7383e-02,\n",
      "        -1.4007e-01,  1.2142e-01,  4.2755e-02, -1.1095e-02, -9.2541e-02,\n",
      "         2.7586e-02,  5.3966e-02,  4.2902e-02,  1.0269e-01, -1.2890e-01,\n",
      "        -1.1012e-01,  1.3674e-01,  1.1942e-01, -1.2688e-02,  7.8467e-02,\n",
      "         1.0111e-01,  1.0202e-01, -6.7225e-02, -5.2163e-02, -7.3904e-02,\n",
      "        -3.8730e-02,  1.3299e-01, -2.8697e-03, -1.1303e-01,  1.0693e-01,\n",
      "         5.5679e-02,  2.2898e-02, -7.4158e-02,  1.0223e-01, -1.1511e-01,\n",
      "         7.0221e-02, -1.7019e-02, -5.1496e-02, -1.2732e-01,  1.9370e-02,\n",
      "        -6.6623e-02, -5.6078e-02,  7.9906e-02, -9.0745e-02,  1.3380e-01,\n",
      "         1.1467e-01,  1.0297e-01,  1.4672e-02, -1.0823e-01, -3.2567e-02,\n",
      "        -6.8332e-02, -1.9879e-02, -1.3181e-01, -6.3520e-02, -2.4465e-02,\n",
      "         7.8231e-06, -3.6479e-02,  2.9658e-02, -7.7083e-02, -9.6337e-02],\n",
      "       requires_grad=True)\n",
      "h_layers.2.weight Parameter containing:\n",
      "tensor([[-0.0871,  0.1106,  0.0709,  ...,  0.1098,  0.0023, -0.0343],\n",
      "        [ 0.0977, -0.0545,  0.0310,  ...,  0.0666,  0.0618,  0.0254],\n",
      "        [-0.1143,  0.0560,  0.1073,  ..., -0.0722, -0.0337, -0.0124],\n",
      "        ...,\n",
      "        [ 0.0589, -0.0669,  0.1005,  ...,  0.0181, -0.0146,  0.0966],\n",
      "        [-0.1059, -0.0557,  0.0168,  ...,  0.1102,  0.0546,  0.0675],\n",
      "        [-0.0544,  0.0478, -0.0517,  ..., -0.0964,  0.1131, -0.0421]],\n",
      "       requires_grad=True)\n",
      "h_layers.2.bias Parameter containing:\n",
      "tensor([ 0.0634,  0.0445, -0.0602, -0.0103, -0.0226,  0.1122,  0.0109,  0.0382,\n",
      "        -0.0726, -0.0610, -0.0895,  0.0545, -0.0978,  0.0577,  0.0599,  0.0201,\n",
      "        -0.0374,  0.0707, -0.0895,  0.0811,  0.0040, -0.0962,  0.0398, -0.0581,\n",
      "         0.0951, -0.0975,  0.0795,  0.0245, -0.1189,  0.0408],\n",
      "       requires_grad=True)\n",
      "out_layer.weight Parameter containing:\n",
      "tensor([[-0.0614,  0.0637,  0.0173, -0.0973,  0.0404, -0.1015, -0.0369, -0.0043,\n",
      "          0.0874,  0.0224, -0.1757,  0.0731, -0.0272, -0.1123,  0.1715,  0.0487,\n",
      "          0.0870, -0.0017, -0.1640,  0.1223,  0.0560, -0.0772,  0.1593, -0.1520,\n",
      "          0.1344,  0.0908,  0.1221,  0.0116, -0.1150,  0.0222],\n",
      "        [-0.1165, -0.0383, -0.0720, -0.1357,  0.1499, -0.1588,  0.1262, -0.0546,\n",
      "         -0.1206,  0.0641, -0.0869,  0.1412,  0.1068,  0.1582,  0.0042, -0.1810,\n",
      "          0.0349, -0.0388,  0.0585,  0.0327, -0.1590,  0.1128, -0.1313, -0.1641,\n",
      "         -0.0396,  0.1765, -0.1182, -0.0019, -0.1111,  0.1076]],\n",
      "       requires_grad=True)\n",
      "out_layer.bias Parameter containing:\n",
      "tensor([-0.0572, -0.1480], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 모델 파라미터 확인\n",
    "for name, param in m1.named_parameters():\n",
    "    print(name, param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습진행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임시 데이터 생성\n",
    "dataTS= torch.FloatTensor(([1,3,5], [2,4,6], [3,5,7], [4,6,8]))\n",
    "targetTS= torch.FloatTensor([[7,9], [8,10], [9,11], [10,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  모델 학습 \n",
    "# pre_y=m1(dataTS)\n",
    "# print(pre_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
