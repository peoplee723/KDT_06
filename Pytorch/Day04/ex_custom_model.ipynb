{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사용자 정의 모델 클래스\n",
    "- 부모 클래스: nn.module\n",
    "- 필수 오버라이딩\n",
    "    - __init__(): 모델 구성 즉, 설계\n",
    "    - forward(): 순방향 학습 진행 코드 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈로딩\n",
    "import torch                                            # 텐서 관련 모듈\n",
    "import torch.nn as nn                                   # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F                         # 인공신경망 관련 함수들 모듈(손실,활성화 함수)\n",
    "import torch.optim as optim                             # 최적화 관련 모듈(가중치, 절편 빠르게 찾아주는 알고리즘)\n",
    "from torchinfo import summary                           # 모델 구조 및 정보 관련 모듈\n",
    "from torchmetrics.regression import *                   # 회귀 성능 지표 관련 모듈\n",
    "from torchmetrics.classification import *               # 분류 성능 지표 관련 모듈\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [기본] 신경망클래스  <hr>\n",
    "    - 입력층 -> 입력: 피쳐수 고정\n",
    "    - 출력층 -> 출력: 타겟수 고정\n",
    "    - 은닉층 -> 고정\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 고정\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 텐서 저장 및 실행 위치 설정\n",
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설계\n",
    "# 데이터셋: 피쳐 4개, 타겟 1개, 회귀\n",
    "# 입력층: 입력 4개, 출력(퍼셉트론) 20개,   AF ReLU\n",
    "# 은닉층: 입력 20개, 출력(퍼셉트론) 100개, AF ReLU\n",
    "# 출력층: 입력 100개, 출력 1개,           AF Sigmoid(2진) & softmax(다중) & X(회귀)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mymodul(nn.Module):\n",
    "    # 인스턴스/객체 생성 시 자동호출되는 메서드\n",
    "    def __init__(self, feature_num, in_out, h_out) -> None:\n",
    "        super().__init__()\n",
    "        # 자식 클래스의 인스턴스 속성 설정\n",
    "        self.input_layer=nn.Linear(feature_num, in_out)   #(4+1)*20= 100 개의 변수\n",
    "        self.hidden_layer=nn.Linear(in_out, h_out) #(20+1)*100=2100개의 변수\n",
    "        self.ouput_layer=nn.Linear(h_out,1)   #101\n",
    "\n",
    "    # forward: 순방향/전방향 학습 진행 시 자동호출되는 메서드(콜백함수-Callback func): 시스템에서 호출됨\n",
    "    # 전달 인자: 학습할 데이터셋\n",
    "    def forward(self, x):\n",
    "        print('calling forward()')\n",
    "        y=self.input_layer(x) #식이 도출\n",
    "        F.relu(y)             #AF통해 결과값 반환 (죽은 렐루 생길 가능성O)\n",
    "\n",
    "        y=self.hidden_layer(y) # 식 도출\n",
    "        F.relu(y)\n",
    "\n",
    "        return self.ouput_layer(y) #최종 식 도출\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은닉층이 동적인 모델\n",
    "class Mymodul2(nn.Module):\n",
    "    # 인스턴스/객체 생성 시 자동호출되는 메서드\n",
    "    def __init__(self, feature_num, in_out, h_list) -> None:\n",
    "        super().__init__()\n",
    "        # 자식 클래스의 인스턴스 속성 설정\n",
    "        self.input_layer=nn.Linear(feature_num, in_out)   #(4+1)*20= 100 개의 변수\n",
    "        self.hidden_layer=nn.Linear(in_out, h_list[0])\n",
    "        for i in range(len(h_list)-1):\n",
    "            name='hidden_layer'+str(i)\n",
    "            self.name=nn.Linear(h_list[i],h_list[i+1])\n",
    "        self.ouput_layer=nn.Linear(h_list[-1],1)   #101\n",
    "\n",
    "    # 순방향/전방향 학습 진행 시 자동호출되는 메서드(콜백함수-Callback func): 시스템에서 호출됨\n",
    "    # 전달 인자: 학습할 데이터셋\n",
    "    def forward(self, x):\n",
    "        print('calling forward()')\n",
    "        y=self.input_layer(x) #식이 도출\n",
    "        F.relu(y)             #AF통해 결과값 반환 (죽은 렐루 생길 가능성O)\n",
    "\n",
    "        y=self.hidden_layer(y) # 식 도출\n",
    "        F.relu(y)\n",
    "\n",
    "        return self.ouput_layer(y) #최종 식 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 20\n",
      "20 30\n",
      "30 40\n",
      "40 50\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(hidden_list)-1):\n",
    "    print(hidden_list[i], hidden_list[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인스턴스 생성\n",
    "m1=Mymodul(4, 50, 100)\n",
    "hidden_list=[10,20,30,40,50]\n",
    "m2=Mymodul2(4, 5, hidden_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4821,  0.2508, -0.2644,  0.2276],\n",
      "        [-0.1710,  0.3457,  0.1973,  0.3884],\n",
      "        [ 0.4702, -0.2332, -0.2673, -0.2689],\n",
      "        [ 0.3315,  0.0348,  0.3407,  0.3394],\n",
      "        [ 0.2080,  0.2115,  0.2604, -0.1670],\n",
      "        [-0.3498, -0.0207,  0.1196, -0.3210],\n",
      "        [-0.0703,  0.1198,  0.0680,  0.1732],\n",
      "        [-0.1902,  0.0087, -0.3969,  0.3766],\n",
      "        [ 0.1050,  0.0554, -0.2852, -0.4941],\n",
      "        [ 0.4021, -0.4446,  0.4639, -0.1727],\n",
      "        [-0.4955,  0.0712, -0.1577, -0.4066],\n",
      "        [ 0.2237,  0.2059, -0.2839, -0.2782],\n",
      "        [ 0.2943, -0.0695, -0.4093,  0.4974],\n",
      "        [-0.2687, -0.4139,  0.1802,  0.3554],\n",
      "        [ 0.4946,  0.4716,  0.2199,  0.4728],\n",
      "        [ 0.0345, -0.4329,  0.1914, -0.2744],\n",
      "        [ 0.3901, -0.2667, -0.4647, -0.3048],\n",
      "        [-0.0050, -0.3938,  0.3122, -0.3797],\n",
      "        [ 0.3278, -0.4235,  0.4145,  0.4686],\n",
      "        [-0.4815, -0.3136, -0.2513,  0.4763],\n",
      "        [-0.1810,  0.1805,  0.4088, -0.1820],\n",
      "        [-0.2922,  0.4839, -0.2784,  0.1655],\n",
      "        [-0.1962, -0.1255, -0.3383, -0.3594],\n",
      "        [ 0.3762,  0.2608,  0.4470,  0.2209],\n",
      "        [ 0.1616, -0.3384,  0.0925,  0.2384],\n",
      "        [-0.3549, -0.0550,  0.2531,  0.1311],\n",
      "        [-0.0604,  0.1560,  0.1732,  0.0784],\n",
      "        [ 0.2383,  0.4411,  0.4107,  0.0786],\n",
      "        [ 0.4554,  0.3508, -0.3824,  0.2311],\n",
      "        [ 0.2727,  0.4762, -0.0271,  0.2224],\n",
      "        [ 0.1843, -0.4782, -0.0587,  0.3346],\n",
      "        [-0.2171,  0.3476, -0.1921,  0.2307],\n",
      "        [-0.1568,  0.3324, -0.0018,  0.1136],\n",
      "        [-0.0138, -0.1020,  0.1026, -0.2911],\n",
      "        [ 0.2183,  0.2595,  0.2876, -0.0878],\n",
      "        [-0.3651,  0.1654,  0.2914, -0.1211],\n",
      "        [-0.2809,  0.1213,  0.4727,  0.4265],\n",
      "        [ 0.1356,  0.0083, -0.2882,  0.4364],\n",
      "        [-0.4326, -0.3039, -0.3287,  0.4974],\n",
      "        [-0.3996,  0.3180, -0.4990,  0.3441],\n",
      "        [ 0.4664,  0.2011, -0.2597,  0.1928],\n",
      "        [-0.0942,  0.1947,  0.4042, -0.1905],\n",
      "        [ 0.1953, -0.1585, -0.3425,  0.2394],\n",
      "        [ 0.0242, -0.1582, -0.1144,  0.2659],\n",
      "        [ 0.0118,  0.4774, -0.4607,  0.4586],\n",
      "        [-0.0156, -0.1979,  0.1233,  0.2771],\n",
      "        [ 0.1078, -0.1970,  0.1570, -0.3852],\n",
      "        [ 0.2962, -0.1139, -0.3837,  0.0374],\n",
      "        [-0.3096, -0.1334,  0.3792,  0.3088],\n",
      "        [ 0.0695,  0.0114,  0.2121, -0.1558]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1825,  0.1446, -0.3744, -0.4369,  0.3013, -0.4912, -0.1071, -0.4288,\n",
      "         0.4250,  0.2431, -0.3025,  0.0029,  0.2834, -0.1019,  0.2541, -0.2179,\n",
      "        -0.3861,  0.0891, -0.2170,  0.4009, -0.2497, -0.4773, -0.3678, -0.1977,\n",
      "        -0.2286, -0.2318, -0.0776,  0.3242, -0.4083, -0.4131, -0.2207, -0.4786,\n",
      "        -0.1185,  0.1462,  0.4118, -0.4808, -0.4653, -0.3416, -0.0459, -0.3301,\n",
      "         0.1044,  0.0882,  0.1505, -0.4081,  0.2524, -0.2640, -0.1408, -0.1332,\n",
      "         0.3390,  0.4046], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1125, -0.0134,  0.0623,  ...,  0.0160, -0.0101,  0.0331],\n",
      "        [-0.1022, -0.0558, -0.0180,  ..., -0.0703,  0.0546,  0.0999],\n",
      "        [-0.0421, -0.1192,  0.1108,  ..., -0.0154,  0.0835, -0.0440],\n",
      "        ...,\n",
      "        [-0.1177,  0.0003, -0.0155,  ...,  0.0441, -0.0026, -0.0618],\n",
      "        [-0.0125,  0.0747,  0.0396,  ..., -0.1155,  0.0707, -0.0985],\n",
      "        [ 0.1051, -0.1279,  0.0086,  ...,  0.0173, -0.1327, -0.1045]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0515,  0.1129,  0.0126, -0.0477, -0.0335,  0.0981,  0.0107,  0.1066,\n",
      "         0.0511, -0.1338, -0.0379, -0.0259,  0.0098, -0.0518,  0.0455,  0.0197,\n",
      "        -0.0457, -0.0369,  0.1314,  0.0046,  0.0857, -0.0576,  0.0910,  0.0871,\n",
      "         0.0257, -0.0182,  0.0174,  0.1375,  0.0751,  0.0226,  0.0612,  0.0323,\n",
      "        -0.0710,  0.0942, -0.0781, -0.0941,  0.0362, -0.1051, -0.0586,  0.0688,\n",
      "         0.1059,  0.0806, -0.1335,  0.0174,  0.0793,  0.0205, -0.0788,  0.1069,\n",
      "        -0.0749, -0.0096,  0.0922,  0.1293,  0.0349,  0.0613, -0.0397,  0.0305,\n",
      "         0.0553,  0.0732, -0.1064, -0.0064, -0.0031,  0.1078,  0.0136,  0.0759,\n",
      "         0.1223,  0.1332, -0.1273, -0.0364,  0.0919,  0.0353, -0.1064, -0.1168,\n",
      "        -0.1175, -0.1127, -0.0487, -0.0966,  0.1045,  0.1214,  0.0732, -0.0713,\n",
      "        -0.0810, -0.0348,  0.0857, -0.1261,  0.0036, -0.0908,  0.0130,  0.0069,\n",
      "         0.0963,  0.1129, -0.1021, -0.0015, -0.0958,  0.0263, -0.0012,  0.0280,\n",
      "        -0.0763, -0.1213,  0.0731,  0.1158], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0514,  0.0319, -0.0936, -0.0180,  0.0216,  0.0537, -0.0791,  0.0995,\n",
      "         -0.0812,  0.0007, -0.0094, -0.0884, -0.0801, -0.0776,  0.0974, -0.0495,\n",
      "          0.0856,  0.0534,  0.0626, -0.0388,  0.0871,  0.0146, -0.0445,  0.0021,\n",
      "          0.0942, -0.0704,  0.0172,  0.0987,  0.0368,  0.0473, -0.0778, -0.0189,\n",
      "          0.0362,  0.0833, -0.0436, -0.0140, -0.0837,  0.0852,  0.0690,  0.0054,\n",
      "         -0.0835,  0.0401, -0.0089, -0.0068, -0.0888,  0.0779,  0.0909, -0.0518,\n",
      "         -0.0884, -0.0011, -0.0598, -0.0687, -0.0610, -0.0716,  0.0597, -0.0799,\n",
      "         -0.0976,  0.0915, -0.0745, -0.0184,  0.0108,  0.0413, -0.0279,  0.0282,\n",
      "         -0.0076, -0.0959,  0.0701, -0.0742, -0.0801, -0.0232, -0.0746,  0.0619,\n",
      "         -0.0577, -0.0073, -0.0466,  0.0473,  0.0816, -0.0651,  0.0011,  0.0731,\n",
      "          0.0124,  0.0923,  0.0184,  0.0455, -0.0660, -0.0425, -0.0935,  0.0149,\n",
      "         -0.0714,  0.0019,  0.0846, -0.0716, -0.0919,  0.0672,  0.0533, -0.0640,\n",
      "         -0.0130,  0.0130,  0.0161,  0.0695]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0351], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 모델 파라미터 확인\n",
    "for m in m1.parameters():print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling forward()\n",
      "tensor([[0.1339],\n",
      "        [0.1097]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 학습진행 -> 모델 인스턴스명(데이터)\n",
    "dataTS=torch.FloatTensor([[1,3,5,7], [2,4,6,8]]) #모델 클래스의 모델 shape에 맞춰야 함!\n",
    "targetTS= torch.FloatTensor([[4], [5]])\n",
    "\n",
    "# 학습\n",
    "pre_y=m1(dataTS)\n",
    "print(pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
