{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사용자 정의 모델 클래스\n",
    "- 부모 클래스: nn.module\n",
    "- 필수 오버라이딩\n",
    "    - __init__(): 모델 구성 즉, 설계\n",
    "    - forward(): 순방향 학습 진행 코드 구현\n",
    "- 동적 모델\n",
    "    - container 모듈 중 nn.ModulList() 사용해서 동적으로 Layer 추가\n",
    "        - forward 기능 미 제공\n",
    "        - layer 인스턴스 요소 사이에 연관성 없음\n",
    "        - layer 인스턴스 요소는 인덱싱으로 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈로딩\n",
    "import torch                                            # 텐서 관련 모듈\n",
    "import torch.nn as nn                                   # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F                         # 인공신경망 관련 함수들 모듈(손실,활성화 함수)\n",
    "import torch.optim as optim                             # 최적화 관련 모듈(가중치, 절편 빠르게 찾아주는 알고리즘)\n",
    "from torchinfo import summary                           # 모델 구조 및 정보 관련 모듈\n",
    "from torchmetrics.regression import *                   # 회귀 성능 지표 관련 모듈\n",
    "from torchmetrics.classification import *               # 분류 성능 지표 관련 모듈\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [기본] 신경망클래스  <hr>\n",
    "    - 입력층 -> 입력: 피쳐수 고정\n",
    "    - 출력층 -> 출력: 타겟수 고정\n",
    "    - 은닉층 -> 고정\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 고정\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 텐서 저장 및 실행 위치 설정\n",
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 설계 - 동적 모델 <hr>\n",
    "    - 목표: 은닉층의 개수가 동적인 모델\n",
    "    - 조건\n",
    "        - 입력층과 출력층 개수 동적 => 입력층의 입력값, 출력층의 출력값\n",
    "        - 은닉층의 개수 동적 => 퍼셉트론 개수 고정 => 은닉층의 개수, 퍼셉트론 수 \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이름: DynamicModel\n",
    "# 부모클래스: nn.Module\n",
    "# 매개변수: in_in, out_out, h_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicModel(nn.Module):\n",
    "    # 생성자 메서드\n",
    "    def __init__(self, in_in, out_out, h_cnt, h_inout) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_layer=nn.Linear(in_in, h_inout)\n",
    "        self.h_layers=nn.ModuleList([nn.Linear(h_inout, h_inout) for _ in range(h_cnt)])\n",
    "        self.out_layer=nn.Linear(h_inout, out_out)\n",
    "\n",
    "    # 학습 진행 콜백 메서드\n",
    "    def forward(self, x):\n",
    "        y=self.in_layer(x)\n",
    "        y=F.relu(y)\n",
    "        \n",
    "        for linear in self.h_layers:\n",
    "            y= linear(y)\n",
    "            y=F.relu(y)\n",
    "        \n",
    "        return self.out_layer(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스 생성\n",
    "m1=DynamicModel(3,1,5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_layer.weight Parameter containing:\n",
      "tensor([[-0.0375, -0.0608, -0.2472],\n",
      "        [-0.3788,  0.0744,  0.0341],\n",
      "        [-0.5093,  0.5015,  0.2614],\n",
      "        [ 0.3550,  0.1704, -0.1549],\n",
      "        [ 0.1970,  0.2679,  0.2267],\n",
      "        [-0.1871, -0.3020, -0.0210],\n",
      "        [ 0.4561, -0.3151, -0.2322],\n",
      "        [-0.2855, -0.4827,  0.2227],\n",
      "        [-0.0830,  0.0576,  0.5631],\n",
      "        [ 0.0916,  0.4499,  0.0932]], requires_grad=True)\n",
      "in_layer.bias Parameter containing:\n",
      "tensor([-0.0614,  0.3518,  0.1764, -0.0674,  0.0194, -0.2808, -0.0461,  0.3831,\n",
      "         0.4893,  0.5314], requires_grad=True)\n",
      "h_layers.0.weight Parameter containing:\n",
      "tensor([[-0.2307, -0.0084,  0.1268,  0.2148, -0.1745, -0.2521,  0.1073, -0.1819,\n",
      "          0.3157, -0.1979],\n",
      "        [ 0.1557, -0.0974, -0.2599, -0.3083,  0.1373, -0.0964, -0.2035,  0.3121,\n",
      "          0.1855,  0.2082],\n",
      "        [-0.1421, -0.0157,  0.0700, -0.0364,  0.1519, -0.0769, -0.0707, -0.0331,\n",
      "         -0.1245, -0.2168],\n",
      "        [-0.0355, -0.1131, -0.0999, -0.1382,  0.1464, -0.0514,  0.2436,  0.0927,\n",
      "         -0.1052,  0.3146],\n",
      "        [-0.0988, -0.2667,  0.2125, -0.1801,  0.2159,  0.2423, -0.1014, -0.1251,\n",
      "          0.1107,  0.1581],\n",
      "        [ 0.2468,  0.0810,  0.0243,  0.2768,  0.0731, -0.2565, -0.0829, -0.0185,\n",
      "          0.1076, -0.3035],\n",
      "        [-0.3144, -0.1801,  0.0405,  0.2145, -0.2634,  0.1311,  0.0165,  0.2791,\n",
      "         -0.1765, -0.0986],\n",
      "        [ 0.1025, -0.3012,  0.2007, -0.1292,  0.0620, -0.1973,  0.2537,  0.0965,\n",
      "          0.0393, -0.1532],\n",
      "        [-0.2298,  0.0251, -0.2178, -0.0133,  0.2754,  0.0890, -0.0870, -0.1147,\n",
      "          0.1305, -0.2536],\n",
      "        [-0.2533, -0.0258,  0.1852, -0.1777, -0.0475, -0.1432,  0.1956, -0.1549,\n",
      "         -0.0454,  0.1471]], requires_grad=True)\n",
      "h_layers.0.bias Parameter containing:\n",
      "tensor([-0.1315,  0.3030, -0.1702, -0.1085,  0.0215, -0.1488, -0.3101, -0.2398,\n",
      "        -0.2848,  0.2830], requires_grad=True)\n",
      "h_layers.1.weight Parameter containing:\n",
      "tensor([[ 0.0214, -0.1559,  0.1185,  0.0163, -0.1547,  0.2071, -0.2056, -0.2215,\n",
      "          0.2239,  0.1567],\n",
      "        [ 0.1484,  0.1052, -0.1328, -0.3047,  0.0059,  0.1695,  0.2069, -0.0544,\n",
      "         -0.1288, -0.0083],\n",
      "        [ 0.2478, -0.0163,  0.2801, -0.1124,  0.0743, -0.2027,  0.0138,  0.2416,\n",
      "         -0.2622,  0.2769],\n",
      "        [ 0.2394,  0.2418, -0.1290,  0.2168,  0.0460, -0.1990,  0.3026, -0.3153,\n",
      "          0.2799,  0.0922],\n",
      "        [ 0.2064,  0.1005, -0.2907,  0.1296, -0.2273, -0.1220, -0.0741, -0.1740,\n",
      "         -0.0521,  0.2196],\n",
      "        [ 0.1633, -0.2129,  0.2058,  0.0645,  0.0375,  0.0273, -0.1564, -0.2622,\n",
      "          0.0725,  0.2736],\n",
      "        [-0.2596,  0.2813,  0.1647,  0.2079,  0.1931,  0.2390,  0.0405, -0.1521,\n",
      "         -0.1825, -0.2569],\n",
      "        [ 0.0149,  0.0413,  0.0611, -0.2067,  0.2193, -0.1723, -0.2772,  0.3109,\n",
      "          0.0740,  0.2544],\n",
      "        [ 0.0205,  0.2894, -0.0098, -0.1258,  0.1531,  0.0597, -0.1214, -0.0711,\n",
      "          0.1434,  0.2175],\n",
      "        [-0.2469, -0.2179,  0.1998,  0.2273, -0.0432, -0.1171,  0.1090,  0.2560,\n",
      "         -0.2072,  0.0753]], requires_grad=True)\n",
      "h_layers.1.bias Parameter containing:\n",
      "tensor([ 0.1756,  0.0886,  0.2962, -0.2944,  0.1814, -0.0291, -0.1561,  0.0747,\n",
      "        -0.0722,  0.2783], requires_grad=True)\n",
      "h_layers.2.weight Parameter containing:\n",
      "tensor([[-0.2231,  0.0422, -0.1164,  0.1717,  0.2400,  0.2152,  0.1019, -0.2914,\n",
      "          0.0428, -0.1784],\n",
      "        [ 0.0987,  0.0443, -0.2662, -0.2253, -0.1597, -0.2798, -0.1229, -0.1196,\n",
      "          0.1774,  0.1515],\n",
      "        [-0.2373, -0.0428,  0.0752, -0.0807,  0.0764, -0.0279, -0.2795,  0.2627,\n",
      "         -0.2279, -0.1402],\n",
      "        [ 0.0338,  0.0966,  0.1026,  0.0857, -0.2540, -0.2574,  0.2672, -0.2628,\n",
      "         -0.0941,  0.1863],\n",
      "        [ 0.2406,  0.2165, -0.1158,  0.1242,  0.1358, -0.2171, -0.2159,  0.0236,\n",
      "          0.2805, -0.1039],\n",
      "        [ 0.0986,  0.2350,  0.1807,  0.1257, -0.0967,  0.1833, -0.3011,  0.0225,\n",
      "          0.0420, -0.0728],\n",
      "        [ 0.2935, -0.2986, -0.2006,  0.2657, -0.0872,  0.0547,  0.0315,  0.2594,\n",
      "          0.0043, -0.0958],\n",
      "        [-0.1180, -0.1018, -0.2209,  0.1112, -0.0197, -0.2002, -0.0857, -0.0666,\n",
      "          0.1059, -0.2175],\n",
      "        [ 0.3064, -0.2917,  0.3074,  0.0027,  0.1200,  0.1070, -0.2712, -0.2843,\n",
      "          0.0500, -0.0710],\n",
      "        [-0.1416, -0.1374, -0.2113,  0.1357, -0.2565, -0.1586,  0.1665,  0.1335,\n",
      "         -0.1151, -0.3025]], requires_grad=True)\n",
      "h_layers.2.bias Parameter containing:\n",
      "tensor([ 0.1529,  0.2600, -0.1524,  0.2774, -0.1580,  0.2193,  0.1393, -0.2525,\n",
      "         0.0816, -0.1626], requires_grad=True)\n",
      "h_layers.3.weight Parameter containing:\n",
      "tensor([[-0.0867,  0.0102, -0.2280,  0.1206,  0.2222, -0.0670,  0.1450, -0.2783,\n",
      "          0.0308, -0.1652],\n",
      "        [ 0.0094, -0.1041, -0.1718, -0.0789, -0.2909, -0.1418, -0.1451,  0.3066,\n",
      "         -0.1582, -0.0082],\n",
      "        [-0.0904, -0.2489,  0.0898, -0.2327,  0.1204, -0.1283,  0.1397,  0.2079,\n",
      "          0.2431,  0.2975],\n",
      "        [-0.0677, -0.3135, -0.1029, -0.3051,  0.0525, -0.2856, -0.0515,  0.2605,\n",
      "         -0.0110,  0.0054],\n",
      "        [ 0.2934, -0.1568, -0.2932,  0.1678,  0.2149, -0.0265, -0.2501,  0.0681,\n",
      "          0.0968, -0.2194],\n",
      "        [-0.1430,  0.0018,  0.1873, -0.0016,  0.2991,  0.2969,  0.0799, -0.1933,\n",
      "         -0.1531, -0.0832],\n",
      "        [ 0.0277, -0.1943, -0.3011, -0.0944, -0.2294,  0.1049, -0.1682, -0.0951,\n",
      "          0.1344,  0.0657],\n",
      "        [ 0.0035,  0.1799, -0.2244,  0.0827,  0.0234, -0.3023,  0.0933, -0.2121,\n",
      "         -0.0815, -0.1487],\n",
      "        [-0.2968,  0.2045,  0.1871,  0.0372, -0.2055,  0.2834, -0.1129, -0.2181,\n",
      "         -0.2318,  0.0446],\n",
      "        [-0.1822, -0.0454, -0.3073, -0.0829, -0.2961, -0.2258, -0.2579, -0.2011,\n",
      "          0.2553, -0.0985]], requires_grad=True)\n",
      "h_layers.3.bias Parameter containing:\n",
      "tensor([-0.2123,  0.3012,  0.0273, -0.2585, -0.2457,  0.0343, -0.2231,  0.1297,\n",
      "        -0.2697, -0.2832], requires_grad=True)\n",
      "h_layers.4.weight Parameter containing:\n",
      "tensor([[ 0.1786, -0.0085,  0.1007, -0.0884, -0.2217,  0.2101, -0.0532,  0.2367,\n",
      "         -0.0865, -0.0669],\n",
      "        [-0.0721, -0.1816,  0.0618,  0.0797, -0.1267, -0.1937,  0.2498, -0.0142,\n",
      "          0.0498, -0.1842],\n",
      "        [ 0.2260,  0.2606,  0.0684,  0.2807,  0.1841,  0.2549, -0.1602, -0.1146,\n",
      "         -0.0510, -0.1597],\n",
      "        [ 0.1628, -0.1743,  0.1076,  0.1727, -0.0585,  0.2878, -0.1484,  0.1389,\n",
      "          0.2146, -0.1910],\n",
      "        [-0.0040,  0.2449, -0.2516, -0.1638, -0.3115,  0.2201,  0.2135,  0.0529,\n",
      "          0.0563, -0.3046],\n",
      "        [ 0.1432, -0.1522,  0.1696, -0.2034, -0.2144,  0.2221,  0.0894, -0.0919,\n",
      "         -0.2043, -0.2771],\n",
      "        [ 0.2227, -0.1078,  0.0685,  0.1882, -0.0781, -0.1486, -0.1763,  0.0270,\n",
      "         -0.0338,  0.0020],\n",
      "        [ 0.0813, -0.2835,  0.1599, -0.0499, -0.2727, -0.1145,  0.0051,  0.2759,\n",
      "          0.3074, -0.1187],\n",
      "        [-0.2156,  0.2466,  0.2562,  0.1832, -0.2923,  0.0532,  0.0715,  0.0947,\n",
      "         -0.2180,  0.0261],\n",
      "        [-0.1248,  0.1978, -0.2079,  0.2676,  0.0889,  0.0767, -0.1435, -0.0185,\n",
      "          0.0787, -0.2400]], requires_grad=True)\n",
      "h_layers.4.bias Parameter containing:\n",
      "tensor([ 0.0426,  0.1707,  0.1263,  0.2649, -0.1599, -0.3148, -0.1237, -0.1792,\n",
      "         0.1809,  0.0966], requires_grad=True)\n",
      "out_layer.weight Parameter containing:\n",
      "tensor([[-0.3011, -0.2232, -0.2846,  0.1036,  0.0796,  0.0239, -0.0895,  0.2762,\n",
      "          0.2425, -0.2858]], requires_grad=True)\n",
      "out_layer.bias Parameter containing:\n",
      "tensor([-0.1995], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 모델 파라미터 확인\n",
    "for name, param in m1.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습진행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임시 데이터 생성\n",
    "dataTS= torch.FloatTensor(([1,3,5], [2,4,6], [3,5,7], [4,6,8]))\n",
    "targetTS= torch.FloatTensor([[7,9], [8,10], [9,11], [10,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2619],\n",
      "        [-0.2620],\n",
      "        [-0.2618],\n",
      "        [-0.2612]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#  모델 학습 \n",
    "pre_y=m1(dataTS)\n",
    "print(pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
