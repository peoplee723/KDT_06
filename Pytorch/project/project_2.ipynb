{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from func import show_outliers\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X_state', 'fmonth', 'idate', 'imonth', 'iday', 'iyear', 'dispcode',\n",
       "       'seqno', 'X_psu', 'ctelenum',\n",
       "       ...\n",
       "       'X_pastae1', 'X_lmtact1', 'X_lmtwrk1', 'X_lmtscl1', 'X_rfseat2',\n",
       "       'X_rfseat3', 'X_flshot6', 'X_pneumo2', 'X_aidtst3', 'X_age80'],\n",
       "      dtype='object', length=330)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_DF=pd.read_csv('brfss2013.csv', encoding='ISO-8859-1', low_memory=False, index_col=0)\n",
    "raw_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Had cholesterol checked in past 5 years\n",
       "Name: X_cholchk, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_DF['X_cholchk'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 처리\n",
    "for col in raw_DF.columns:\n",
    "    # print(raw_DF[col].dtype)\n",
    "    if raw_DF[col].dtype=='int' or raw_DF[col].dtype=='float64':\n",
    "        raw_DF[col].fillna(raw_DF[col].median(), inplace=True)\n",
    "    elif raw_DF[col].dtype=='object':\n",
    "        raw_DF[col].fillna(raw_DF[col].mode(dropna=True), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         None\n",
       "2         None\n",
       "3         None\n",
       "4         None\n",
       "5         None\n",
       "          ... \n",
       "491771    None\n",
       "491772    None\n",
       "491773    None\n",
       "491774    None\n",
       "491775    None\n",
       "Name: X_flshot6, Length: 491775, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_DF['X_flshot6']=raw_DF['X_flshot6'].fillna(raw_DF['X_flshot6'].mode(), inplace=True)\n",
    "raw_DF['X_flshot6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Yes\n",
       "Name: X_flshot6, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_DF['X_flshot6'].mode(dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_state</th>\n",
       "      <th>fmonth</th>\n",
       "      <th>idate</th>\n",
       "      <th>imonth</th>\n",
       "      <th>iday</th>\n",
       "      <th>iyear</th>\n",
       "      <th>dispcode</th>\n",
       "      <th>seqno</th>\n",
       "      <th>X_psu</th>\n",
       "      <th>ctelenum</th>\n",
       "      <th>...</th>\n",
       "      <th>X_pastae1</th>\n",
       "      <th>X_lmtact1</th>\n",
       "      <th>X_lmtwrk1</th>\n",
       "      <th>X_lmtscl1</th>\n",
       "      <th>X_rfseat2</th>\n",
       "      <th>X_rfseat3</th>\n",
       "      <th>X_flshot6</th>\n",
       "      <th>X_pneumo2</th>\n",
       "      <th>X_aidtst3</th>\n",
       "      <th>X_age80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>January</td>\n",
       "      <td>1092013.0</td>\n",
       "      <td>January</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Completed interview</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Did not meet both guidelines</td>\n",
       "      <td>Told have arthritis and have limited usual act...</td>\n",
       "      <td>Told have arthritis and have limited work</td>\n",
       "      <td>Told have arthritis and social activities limi...</td>\n",
       "      <td>Always or almost always wear seat belt</td>\n",
       "      <td>Always wear seat belt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>January</td>\n",
       "      <td>1192013.0</td>\n",
       "      <td>January</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Completed interview</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Did not meet both guidelines</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Always or almost always wear seat belt</td>\n",
       "      <td>Always wear seat belt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>January</td>\n",
       "      <td>1192013.0</td>\n",
       "      <td>January</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Completed interview</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Did not meet both guidelines</td>\n",
       "      <td>Told have arthritis and have limited usual act...</td>\n",
       "      <td>Told have arthritis and have limited work</td>\n",
       "      <td>Told have arthritis and social activities limi...</td>\n",
       "      <td>Always or almost always wear seat belt</td>\n",
       "      <td>Always wear seat belt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>January</td>\n",
       "      <td>1112013.0</td>\n",
       "      <td>January</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Completed interview</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Did not meet both guidelines</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Always or almost always wear seat belt</td>\n",
       "      <td>Always wear seat belt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>February</td>\n",
       "      <td>2062013.0</td>\n",
       "      <td>February</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Completed interview</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Did not meet both guidelines</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Always or almost always wear seat belt</td>\n",
       "      <td>Always wear seat belt</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491771</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>June</td>\n",
       "      <td>6212013.0</td>\n",
       "      <td>June</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Completed interview</td>\n",
       "      <td>2.013005e+09</td>\n",
       "      <td>2.013005e+09</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Did not meet both guidelines</td>\n",
       "      <td>Told have arthritis and no limited usual activ...</td>\n",
       "      <td>Told have arthritis and no limited work</td>\n",
       "      <td>Told have arthritis and social activities limi...</td>\n",
       "      <td>Always or almost always wear seat belt</td>\n",
       "      <td>Always wear seat belt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491772</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>June</td>\n",
       "      <td>6222013.0</td>\n",
       "      <td>June</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Completed interview</td>\n",
       "      <td>2.013005e+09</td>\n",
       "      <td>2.013005e+09</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Did not meet both guidelines</td>\n",
       "      <td>Told have arthritis and have limited usual act...</td>\n",
       "      <td>Told have arthritis and have limited work</td>\n",
       "      <td>Told have arthritis and social activities not ...</td>\n",
       "      <td>Always or almost always wear seat belt</td>\n",
       "      <td>Always wear seat belt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491773</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>July</td>\n",
       "      <td>8062013.0</td>\n",
       "      <td>August</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Partially completed interview</td>\n",
       "      <td>2.013005e+09</td>\n",
       "      <td>2.013005e+09</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Did not meet both guidelines</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Always or almost always wear seat belt</td>\n",
       "      <td>Always wear seat belt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491774</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>July</td>\n",
       "      <td>8052013.0</td>\n",
       "      <td>August</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Completed interview</td>\n",
       "      <td>2.013005e+09</td>\n",
       "      <td>2.013005e+09</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Did not meet both guidelines</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Not told they have arthritis</td>\n",
       "      <td>Always or almost always wear seat belt</td>\n",
       "      <td>Always wear seat belt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491775</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>July</td>\n",
       "      <td>7282013.0</td>\n",
       "      <td>July</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Completed interview</td>\n",
       "      <td>2.013005e+09</td>\n",
       "      <td>2.013005e+09</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>491775 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X_state    fmonth      idate    imonth  iday   iyear  \\\n",
       "1           Alabama   January  1092013.0   January   9.0  2013.0   \n",
       "2           Alabama   January  1192013.0   January  19.0  2013.0   \n",
       "3           Alabama   January  1192013.0   January  19.0  2013.0   \n",
       "4           Alabama   January  1112013.0   January  11.0  2013.0   \n",
       "5           Alabama  February  2062013.0  February   6.0  2013.0   \n",
       "...             ...       ...        ...       ...   ...     ...   \n",
       "491771  Puerto Rico      June  6212013.0      June  21.0  2013.0   \n",
       "491772  Puerto Rico      June  6222013.0      June  22.0  2013.0   \n",
       "491773  Puerto Rico      July  8062013.0    August   6.0  2013.0   \n",
       "491774  Puerto Rico      July  8052013.0    August   5.0  2013.0   \n",
       "491775  Puerto Rico      July  7282013.0      July  28.0  2013.0   \n",
       "\n",
       "                             dispcode         seqno         X_psu ctelenum  \\\n",
       "1                 Completed interview  2.013001e+09  2.013001e+09      Yes   \n",
       "2                 Completed interview  2.013001e+09  2.013001e+09      Yes   \n",
       "3                 Completed interview  2.013001e+09  2.013001e+09      Yes   \n",
       "4                 Completed interview  2.013001e+09  2.013001e+09      Yes   \n",
       "5                 Completed interview  2.013001e+09  2.013001e+09      Yes   \n",
       "...                               ...           ...           ...      ...   \n",
       "491771            Completed interview  2.013005e+09  2.013005e+09      Yes   \n",
       "491772            Completed interview  2.013005e+09  2.013005e+09      Yes   \n",
       "491773  Partially completed interview  2.013005e+09  2.013005e+09      Yes   \n",
       "491774            Completed interview  2.013005e+09  2.013005e+09      Yes   \n",
       "491775            Completed interview  2.013005e+09  2.013005e+09      Yes   \n",
       "\n",
       "        ...                     X_pastae1  \\\n",
       "1       ...  Did not meet both guidelines   \n",
       "2       ...  Did not meet both guidelines   \n",
       "3       ...  Did not meet both guidelines   \n",
       "4       ...  Did not meet both guidelines   \n",
       "5       ...  Did not meet both guidelines   \n",
       "...     ...                           ...   \n",
       "491771  ...  Did not meet both guidelines   \n",
       "491772  ...  Did not meet both guidelines   \n",
       "491773  ...  Did not meet both guidelines   \n",
       "491774  ...  Did not meet both guidelines   \n",
       "491775  ...                           NaN   \n",
       "\n",
       "                                                X_lmtact1  \\\n",
       "1       Told have arthritis and have limited usual act...   \n",
       "2                            Not told they have arthritis   \n",
       "3       Told have arthritis and have limited usual act...   \n",
       "4                            Not told they have arthritis   \n",
       "5                            Not told they have arthritis   \n",
       "...                                                   ...   \n",
       "491771  Told have arthritis and no limited usual activ...   \n",
       "491772  Told have arthritis and have limited usual act...   \n",
       "491773                       Not told they have arthritis   \n",
       "491774                       Not told they have arthritis   \n",
       "491775                                                NaN   \n",
       "\n",
       "                                        X_lmtwrk1  \\\n",
       "1       Told have arthritis and have limited work   \n",
       "2                    Not told they have arthritis   \n",
       "3       Told have arthritis and have limited work   \n",
       "4                    Not told they have arthritis   \n",
       "5                    Not told they have arthritis   \n",
       "...                                           ...   \n",
       "491771    Told have arthritis and no limited work   \n",
       "491772  Told have arthritis and have limited work   \n",
       "491773               Not told they have arthritis   \n",
       "491774               Not told they have arthritis   \n",
       "491775                                        NaN   \n",
       "\n",
       "                                                X_lmtscl1  \\\n",
       "1       Told have arthritis and social activities limi...   \n",
       "2                            Not told they have arthritis   \n",
       "3       Told have arthritis and social activities limi...   \n",
       "4                            Not told they have arthritis   \n",
       "5                            Not told they have arthritis   \n",
       "...                                                   ...   \n",
       "491771  Told have arthritis and social activities limi...   \n",
       "491772  Told have arthritis and social activities not ...   \n",
       "491773                       Not told they have arthritis   \n",
       "491774                       Not told they have arthritis   \n",
       "491775                                                NaN   \n",
       "\n",
       "                                     X_rfseat2              X_rfseat3  \\\n",
       "1       Always or almost always wear seat belt  Always wear seat belt   \n",
       "2       Always or almost always wear seat belt  Always wear seat belt   \n",
       "3       Always or almost always wear seat belt  Always wear seat belt   \n",
       "4       Always or almost always wear seat belt  Always wear seat belt   \n",
       "5       Always or almost always wear seat belt  Always wear seat belt   \n",
       "...                                        ...                    ...   \n",
       "491771  Always or almost always wear seat belt  Always wear seat belt   \n",
       "491772  Always or almost always wear seat belt  Always wear seat belt   \n",
       "491773  Always or almost always wear seat belt  Always wear seat belt   \n",
       "491774  Always or almost always wear seat belt  Always wear seat belt   \n",
       "491775                                     NaN                    NaN   \n",
       "\n",
       "        X_flshot6  X_pneumo2 X_aidtst3  X_age80  \n",
       "1             NaN        NaN        No     60.0  \n",
       "2             NaN        NaN       Yes     50.0  \n",
       "3             NaN        NaN       Yes     55.0  \n",
       "4             NaN        NaN        No     64.0  \n",
       "5              No         No        No     66.0  \n",
       "...           ...        ...       ...      ...  \n",
       "491771        NaN        NaN        No     58.0  \n",
       "491772        NaN        NaN        No     62.0  \n",
       "491773        NaN        NaN       Yes     37.0  \n",
       "491774        NaN        NaN       Yes     30.0  \n",
       "491775        NaN        NaN       NaN     57.0  \n",
       "\n",
       "[491775 rows x 330 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_DF.dropna(how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.classification import F1Score, BinaryF1Score, Accuracy\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from get_dataset import *\n",
    "from get_model import *\n",
    "from get_train_model import *\n",
    "from func import Torch_proccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_TS= Torch_proccesing(raw_DF)\n",
    "clf_TS.feature=clf_TS.data.drop(columns='genhlth')\n",
    "clf_TS.target= clf_TS.data['genhlth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, Y_train, Y_test\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf_TS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf_TS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclf_TS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X_train, X_val, Y_train, Y_val\u001b[38;5;241m=\u001b[39mtrain_test_split(X_train, Y_train,\n\u001b[0;32m      4\u001b[0m                                                 random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m,\n\u001b[0;32m      5\u001b[0m                                                 stratify\u001b[38;5;241m=\u001b[39mY_train)\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2638\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2634\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2636\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2638\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2640\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2641\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2642\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2643\u001b[0m     )\n\u001b[0;32m   2644\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2197\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   2165\u001b[0m \n\u001b[0;32m   2166\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2195\u001b[0m \u001b[38;5;124;03m    to an integer.\u001b[39;00m\n\u001b[0;32m   2196\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2197\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\sklearn\\utils\\validation.py:109\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _object_dtype_isnan(X)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 109\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput contains NaN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# We need only consider float arrays, hence can early return for all else.\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xp\u001b[38;5;241m.\u001b[39misdtype(X\u001b[38;5;241m.\u001b[39mdtype, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal floating\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplex floating\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test= train_test_split(clf_TS.feature, clf_TS.target, \n",
    "                                                    random_state=123,stratify=clf_TS.target)\n",
    "X_train, X_val, Y_train, Y_val=train_test_split(X_train, Y_train,\n",
    "                                                random_state=123,\n",
    "                                                stratify=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= RandomForestClassifier(verbose=2)\n",
    "clf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X_state  fmonth  idate  imonth  iday   iyear  dispcode  seqno  X_psu  ctelenum  pvtresd1  colghous  stateres  cellfon3  ladult  numadult  nummen  numwomen  genhlth  physhlth  menthlth  poorhlth  hlthpln1  persdoc2  medcost  checkup1  sleptim1  bphigh4  bpmeds  bloodcho  cholchk  toldhi2  cvdinfr4  cvdcrhd4  cvdstrk3  asthma3  asthnow  chcscncr  chcocncr  chccopd1  havarth3  addepev2  chckidny  diabete3  veteran3  marital  children  educa  employ1  income2  weight2  height3  numhhol2  numphon2  cpdemo1  cpdemo4  internet  renthom1  sex    pregnant  qlactlm2  useequip  blind  decide  diffwalk  diffdres  diffalon  smoke100  smokday2  stopsmk2  lastsmk2  usenow3  alcday5  avedrnk2  drnk3ge5  maxdrnks  fruitju1  fruit1  fvbeans  fvgreen  fvorang  vegetab1  exerany2  exract11  exeroft1  exerhmm1  exract21  exeroft2  exerhmm2  strength  lmtjoin3  arthdis2  arthsocl  joinpain  seatbelt  flushot6  flshtmy2  tetanus  pneuvac3  hivtst6  hivtstd3  whrtst10  pdiabtst  prediab1  diabage2  insulin  bldsugar  feetchk2  doctdiab  chkhemo3  feetchk  eyeexam  diabeye  diabedu  painact2  qlmentl2  qlstres2  qlhlth2  medicare  hlthcvrg  delaymed  dlyother  nocov121  lstcovrg  drvisits  medscost  carercvd  medbills  ssbsugar  ssbfrut2  wtchsalt  longwtch  dradvise  asthmage  asattack  aservist  asdrvist  asrchkup  asactlim  asymptom  asnoslep  asthmed3  asinhalr  harehab1  strehab1  cvdasprn  aspunsaf  rlivpain  rduchart  rducstrk  arttoday  arthwgt  arthexer  arthedu  imfvplac  hpvadvc2  hpvadsht  hadmam  howlong  profexam  lengexam  hadpap2  lastpap2  hadhyst2  bldstool  lstblds3  hadsigm3  hadsgco1  lastsig3  pcpsaad2  pcpsadi1  pcpsare1  psatest1  psatime  pcpsars1  pcpsade1  pcdmdecn  rrclass2  rrcognt2  rratwrk2  rrhcare3  rrphysm2  rremtsm2  misnervs  mishopls  misrstls  misdeprd  miseffrt  miswtles  misnowrk  mistmnt  mistrhlp  misphlpf  scntmony  scntmeal  scntpaid  scntwrk1  scntlpad  scntlwk1  scntvot1  rcsgendr  rcsrltn2  casthdx2  casthno2  emtsuprt  lsatisfy  ctelnum1  cellfon2  cadult  pvtresd2  cclghous  cstate  landline  pctcell  qstver  qstlang  mscode  X_ststr  X_strwt  X_rawrake  X_wt2rake  X_imprace  X_impnph  X_impeduc  X_impmrtl  X_imphome  X_chispnc  X_crace1  X_impcage  X_impcrac  X_impcsex  X_cllcpwt  X_dualuse  X_dualcor  X_llcpwt2  X_llcpwt  X_rfhlth  X_hcvu651  X_rfhype5  X_cholchk  X_rfchol  X_ltasth1  X_casthm1  X_asthms1  X_drdxar1  X_prace1  X_mrace1  X_hispanc  X_race  X_raceg21  X_racegr3  X_race_g1  X_ageg5yr  X_age65yr  X_age_g  htin4  htm4   wtkg3  X_bmi5  X_bmi5cat  X_rfbmi5  X_chldcnt  X_educag  X_incomg  X_smoker3  X_rfsmok3  drnkany5  drocdy3_  X_rfbing5  X_drnkdy4  X_drnkmo4  X_rfdrhv4  X_rfdrmn4  X_rfdrwm4  ftjuda1_  frutda1_  beanday_  grenday_  orngday_  vegeda1_  X_misfrtn  X_misvegn  X_frtresp  X_vegresp  X_frutsum  X_vegesum  X_frtlt1  X_veglt1  X_frt16  X_veg23  X_fruitex  X_vegetex  X_totinda  metvl11_  metvl21_  maxvo2_  fc60_  actin11_  actin21_  padur1_  padur2_  pafreq1_  pafreq2_  X_minac11  X_minac21  strfreq_  pamiss1_  pamin11_  pamin21_  pa1min_  pavig11_  pavig21_  pa1vigm_  X_pacat1  X_paindx1  X_pa150r2  X_pa300r2  X_pa30021  X_pastrng  X_parec1  X_pastae1  X_lmtact1  X_lmtwrk1  X_lmtscl1  X_rfseat2  X_rfseat3  X_flshot6  X_pneumo2  X_aidtst3  X_age80\n",
       "False    False   False  False   False  False  False     False  False  False     True      True      True      True      True    True      True    True      False    False     False     True      False     False     False    False     False     False    True    False     False    False    False     False     False     False    True     False     False     False     False     False     False     False     False     False    False     False  False    False    False    False    True      True      True     True     False     False     False  True      False     False     False  False   False     False     False     False     True      True      True      False    False    False     False     False     False     False   False    False    False    False     False     False     False     False     False     False     False     False     True      True      True      True      False     False     True      False    False     False    True      True      True      True      True      True     True      True      True      True      True     True     True     True     True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True     True      True      True      True    True     True      True      True     True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      False     False     False   False     True      False   False     True     False   False    True    False    False    False      False      False      True      True       True       True       True       True      True       True       True       True       False      True       False      False     False     False      False      False      False     False      False      False      False      False     False     False      False   False      False      False      False      False      False    False  False  False  False   False      False     False      False     False     False      False      False     False     False      False      False      False      False      True       False     False     False     False     False     False     False      False      False      False      False      False      False     False     False    False    False      False      False      False     False     False    False  False     False     False    False    False     False     False      False      False     False     False     False     False    False     False     False     False     False      False      False      False      False      False     False      False      False      False      False      False      True       True       False      False      108\n",
       "                                                                                False     True      False     False     True    False     False   False     False    False     False     True      False     False     False    False     False     False    True    False     False    False    False     False     False     False    True     False     False     False     False     False     False     False     False     False    False     False  False    False    False    False    False     True      False    False    False     False     False  True      False     False     False  False   False     False     False     False     True      True      True      False    False    False     False     False     False     False   False    False    False    False     False     False     False     False     False     False     False     False     True      True      True      True      False     False     False     False    False     False    True      True      True      True      True      True     True      True      True      True      True     True     True     True     True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True     True      True      True      True    True     True      True      True     True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True    True      True      True    True      True     False   False    False   False    False    False      False      False      False     True       True       True       True       True      True       True       True       True       False      True       False      False     False     False      False      False      False     False      False      False      False      False     False     False      False   False      False      False      False      False      False    False  False  False  False   False      False     False      False     False     False      False      False     False     False      False      False      False      True       False      False     False     False     False     False     False     False      False      False      False      False      False      False     False     False    False    False      False      False      False     False     False    False  False     False     False    False    False     False     False      False      False     False     False     False     False    False     False     False     False     False      False      False      False      False      False     False      False      False      False      False      False      True       True       False      False      100\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      True      False    False     False    True      True      True      True      True      True     True      True      True      True      True     True     True     True     True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True     True      True      True      True    True     True      True      True     True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True    True      True      True    True      True     False   False    False   False    False    False      False      False      False     True       True       True       True       True      True       True       True       True       False      True       False      False     False     False      False      False      False     False      False      False      False      False     False     False      False   False      False      False      False      False      False    False  False  False  False   False      False     False      False     False     False      False      False     False     False      False      False      False      True       False      False     False     False     False     False     False     False      False      False      False      False      False      False     False     False    False    False      False      False      False     False     False    False  False     False     False    False    False     False     False      False      False     False     False     False     False    False     False     False     False     False      False      False      False      False      False     False      False      False      False      False      False      True       True       False      False      100\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          False     False     False     True      False     True      False     False     False     False     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True     True      True      True      True    True     True      True      True     True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True    True      True      True    True      True     False   False    False   False    False    False      False      False      False     True       True       True       True       True      True       True       True       True       False      True       False      False     False     False      False      False      False     False      False      False      False      False     False     False      False   False      False      False      False      False      False    False  False  False  False   False      False     False      False     False     False      False      False     False     False      False      False      False      True       False      False     False     False     False     False     False     False      False      False      False      False      False      False     False     False    False    False      False      False      False     False     False    False  False     False     False    False    False     False     False      False      False     False     False     False     False    False     False     False     False     False      False      False      False      False      False     False      False      False      False      False      False      True       True       False      False       89\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True     True      True      True      True    True     True      True      True     True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True    True      True      True    True      True     False   False    False   False    False    False      False      False      False     True       True       True       True       True      True       True       True       True       False      True       False      False     False     False      False      False      False     False      False      False      False      False     False     False      False   False      False      False      False      False      False    False  False  False  False   False      False     False      False     False     False      False      False     False     False      False      False      False      False      True       False     False     False     False     False     False     False      False      False      False      False      False      False     False     False    False    False      False      False      False     False     False    False  False     False     False    False    False     False     False      False      False     False     False     False     False    False     False     False     False     False      False      False      False      False      False     False      False      False      False      False      False      True       True       False      False       83\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ... \n",
       "                                                                                                                                                                                                                                                             False   False     False    False    False     False     False     False    False    False     False     False     False     False     False     False     False     False    False     False  False    False    False    False    False     True      False    False    False     False     False  True      False     False     False  False   False     False     False     False     False     True      False     False    False    True      True      True      False     False   False    False    False    False     False     False     False     False     False     False     False     False     False     False     False     False     False     False     False     False    False     False    False     False     False     False     True      True     True      True      True      True      True     True     True     True     True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True     True      True      True      True    True     True      True      True     True      True      False     True      False     False     False     True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True    True      True      True    True      True     False   False    False   False    False    False      False      False      False     True       True       True       True       True      True       True       True       True       False      True       False      False     False     False      False      False      False     False      False      False      False      False     False     False      False   False      False      False      False      False      False    False  False  False  False   False      False     False      False     False     False      False      False     False     False      False      False      False      True       False      False     False     False     False     False     False     False      False      False      False      False      False      False     False     False    False    False      False      False      False     False     False    False  False     False     False    False    False     False     False      False      False     False     False     False     False    False     False     False     False     False      False      False      False      False      False     False      False      False      False      False      False      True       True       False      False        1\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  False     False     False     True      True      True      True      True      True      True      True      True      True      False     True      False     True      False     False     False     False     False    False     False    True      True      True      True    True     True      True      True     True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True    True      True      True    True      True     False   False    False   False    False    False      False      False      False     True       True       True       True       True      True       True       True       True       False      True       False      False     False     True       False      False      False     False      False      False      False      False     False     False      False   False      False      False      False      False      False    False  False  False  False   False      False     False      False     False     False      False      False     False     False      False      False      False      False      True       False     False     False     False     False     False     False      False      False      False      False      False      False     False     False    False    False      False      False      False     False     False    False  False     False     False    False    False     False     False      False      False     False     False     False     False    False     False     False     False     False      False      False      False      False      False     False      False      False      False      False      False      False      False      False      False        1\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          False     False     False     True      False     True      False     False     False     False     True      True      False     False     False     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True     True      True      True      True    True     True      True      True     True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True      False     False     False     False     True      True      False     True      True      True      True      True      True      True      True      True    True      True      True    True      True     False   False    False   False    False    False      False      False      False     True       True       True       True       True      True       True       True       True       False      True       False      False     False     False      False      False      False     False      False      False      False      False     False     False      False   False      False      False      False      False      False    False  False  False  False   False      False     False      False     False     False      False      False     False     False      False      False      False      True       False      False     False     False     False     False     False     False      False      False      False      False      False      False     False     False    False    False      False      False      False     False     False    False  False     False     False    False    False     False     False      False      False     False     False     False     False    False     False     False     False     False      False      False      False      False      False     False      False      False      False      False      False      True       True       False      False        1\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        False     False     True      True      True      True      True     True      True     True      True      True      True    True     True      True      True     True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True    True      True      True    True      True     False   False    False   False    False    False      False      False      False     True       True       True       True       True      True       True       True       True       False      True       False      False     False     False      False      False      False     False      False      False      False      False     False     False      False   False      False      False      False      False      False    False  False  False  False   False      False     False      False     False     False      False      False     False     False      False      False      False      False      True       False     False     False     False     False     False     False      False      False      False      False      False      False     False     False    False    False      False      False      False     False     False    False  False     False     False    False    False     False     False      False      False     False     False     False     False    False     False     False     False     False      False      False      False      False      False     False      False      False      False      False      False      True       True       False      False        1\n",
       "         True    True   True    True   True   True      True   True   True      True      True      True      True      True    True      True    True      True     True      True      True      True      True      True     True      True      True     True    True      True     True     True      True      True      True     True     True      True      True      True      True      True      True      True      True     True      True   True     True     True     True     True      True      True     True     True      True      True   True      True      True      True   True    True      True      True      True      True      True      True      True     True     True      True      True      True      True    True     True     True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True     True      True      True      True      True      True     True      True      True      True      True     True     True     True     True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True     True      True      True      True    True     True      True      True     True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True     True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True      True    True      True      True    True      True     True    True     True    True     True     True       True       True       True      True       True       True       True       True      True       True       True       True       True       True       True       True      True      True       True       True       True      True       True       True       True       True      True      True       True    True       True       True       True       True       True     True   True   True   True    True       True      True       True      True      True       True       True      True      True       True       True       True       True       True       True      True      True      True      True      True      True       True       True       True       True       True       True      True      True     True     True       True       True       True      True      True     True   True      True      True     True     True      True      True       True       True      True      True      True      True     True      True      True      True      True       True       True       True       True       True      True       True       True       True       True       True       True       True       True       False        1\n",
       "Name: count, Length: 421854, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_DF=life_DF[9:]\n",
    "life_col= life_DF.columns\n",
    "for co in life_col:\n",
    "    if life_DF[co].dtype=='object' and co != 'genhlth':\n",
    "        life_DF[co].bfill()\n",
    "        life_DF[co]=LabelEncoder().fit_transform(life_DF[co])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_DF['genhlth']=life_DF['genhlth'].bfill()\n",
    "life_DF['genhlth'].replace({'Poor':0, 'Fair':1, 'Good':2, 'Very good':3, 'Excellent':4},\n",
    "                                   inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2]-1 학습 모델 설계\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2]-2 데이터셋 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "life= Torch_proccesing(life_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# life_T.data['genhlth'].replace({'Poor':0, 'Fair':1, 'Good':2, 'Very good':3, 'Excellent':4},\n",
    "#                                    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employ -> 원핫 인코딩\n",
    "# em= ['Unable to work', 'Out of work for 1 year or more', 'A student', 'Out of work for less than 1 year',\n",
    "#      'A homemaker', 'Self-employed', 'Retired', 'Employed for wages']\n",
    "# value= [1,2,3,4,5,6,7,8]\n",
    "# life_T.data=pd.get_dummies(life_T.data, columns=['employ'], drop_first=True, sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 491766 entries, 10 to 491775\n",
      "Columns: 330 entries, X_state to X_age80\n",
      "dtypes: float64(99), int32(230), int64(1)\n",
      "memory usage: 810.4 MB\n"
     ]
    }
   ],
   "source": [
    "life.data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_state fmonth idate imonth iday iyear dispcode seqno X_psu ctelenum pvtresd1 colghous stateres cellfon3 ladult numadult nummen numwomen genhlth physhlth menthlth poorhlth hlthpln1 persdoc2 medcost checkup1 sleptim1 bphigh4 bpmeds bloodcho cholchk toldhi2 cvdinfr4 cvdcrhd4 cvdstrk3 asthma3 asthnow chcscncr chcocncr chccopd1 havarth3 addepev2 chckidny diabete3 veteran3 marital children educa employ1 income2 weight2 height3 numhhol2 numphon2 cpdemo1 cpdemo4 internet renthom1 sex pregnant qlactlm2 useequip blind decide diffwalk diffdres diffalon smoke100 smokday2 stopsmk2 lastsmk2 usenow3 alcday5 avedrnk2 drnk3ge5 maxdrnks fruitju1 fruit1 fvbeans fvgreen fvorang vegetab1 exerany2 exract11 exeroft1 exerhmm1 exract21 exeroft2 exerhmm2 strength lmtjoin3 arthdis2 arthsocl joinpain seatbelt flushot6 flshtmy2 tetanus pneuvac3 hivtst6 hivtstd3 whrtst10 pdiabtst prediab1 diabage2 insulin bldsugar feetchk2 doctdiab chkhemo3 feetchk eyeexam diabeye diabedu painact2 qlmentl2 qlstres2 qlhlth2 medicare hlthcvrg delaymed dlyother nocov121 lstcovrg drvisits medscost carercvd medbills ssbsugar ssbfrut2 wtchsalt longwtch dradvise asthmage asattack aservist asdrvist asrchkup asactlim asymptom asnoslep asthmed3 asinhalr harehab1 strehab1 cvdasprn aspunsaf rlivpain rduchart rducstrk arttoday arthwgt arthexer arthedu imfvplac hpvadvc2 hpvadsht hadmam howlong profexam lengexam hadpap2 lastpap2 hadhyst2 bldstool lstblds3 hadsigm3 hadsgco1 lastsig3 pcpsaad2 pcpsadi1 pcpsare1 psatest1 psatime pcpsars1 pcpsade1 pcdmdecn rrclass2 rrcognt2 rratwrk2 rrhcare3 rrphysm2 rremtsm2 misnervs mishopls misrstls misdeprd miseffrt miswtles misnowrk mistmnt mistrhlp misphlpf scntmony scntmeal scntpaid scntwrk1 scntlpad scntlwk1 scntvot1 rcsgendr rcsrltn2 casthdx2 casthno2 emtsuprt lsatisfy ctelnum1 cellfon2 cadult pvtresd2 cclghous cstate landline pctcell qstver qstlang mscode X_ststr X_strwt X_rawrake X_wt2rake X_imprace X_impnph X_impeduc X_impmrtl X_imphome X_chispnc X_crace1 X_impcage X_impcrac X_impcsex X_cllcpwt X_dualuse X_dualcor X_llcpwt2 X_llcpwt X_rfhlth X_hcvu651 X_rfhype5 X_cholchk X_rfchol X_ltasth1 X_casthm1 X_asthms1 X_drdxar1 X_prace1 X_mrace1 X_hispanc X_race X_raceg21 X_racegr3 X_race_g1 X_ageg5yr X_age65yr X_age_g htin4 htm4 wtkg3 X_bmi5 X_bmi5cat X_rfbmi5 X_chldcnt X_educag X_incomg X_smoker3 X_rfsmok3 drnkany5 drocdy3_ X_rfbing5 X_drnkdy4 X_drnkmo4 X_rfdrhv4 X_rfdrmn4 X_rfdrwm4 ftjuda1_ frutda1_ beanday_ grenday_ orngday_ vegeda1_ X_misfrtn X_misvegn X_frtresp X_vegresp X_frutsum X_vegesum X_frtlt1 X_veglt1 X_frt16 X_veg23 X_fruitex X_vegetex X_totinda metvl11_ metvl21_ maxvo2_ fc60_ actin11_ actin21_ padur1_ padur2_ pafreq1_ pafreq2_ X_minac11 X_minac21 strfreq_ pamiss1_ pamin11_ pamin21_ pa1min_ pavig11_ pavig21_ pa1vigm_ X_pacat1 X_paindx1 X_pa150r2 X_pa300r2 X_pa30021 X_pastrng X_parec1 X_pastae1 X_lmtact1 X_lmtwrk1 X_lmtscl1 X_rfseat2 X_rfseat3 X_flshot6 X_pneumo2 X_aidtst3 X_age80 "
     ]
    }
   ],
   "source": [
    "for col in life.data.columns:\n",
    "    print(col, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 피쳐와 타겟 선정\n",
    "life.feature=life.data.drop(columns='genhlth')\n",
    "life.target= life.data['genhlth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (276618, 329),(276618,)\n",
      "test: (122942, 329),(122942,)\n",
      "val: (92206, 329),(92206,)\n",
      "train: (368824, 329),(368824,)\n",
      "test: (122942, 329),(122942,)\n"
     ]
    }
   ],
   "source": [
    "# 테이터 분리\n",
    "life.split(val=True, random_state=921, stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링 -> minmax\n",
    "scaler= MinMaxScaler()\n",
    "scaler.fit(life.X_train)\n",
    "X_train_scaled=scaler.transform(life.X_train)\n",
    "X_test_scaled= scaler.transform(life.X_test)\n",
    "X_val_scaled= scaler.transform(life.X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled=pd.DataFrame(X_train_scaled, columns=life.feature.columns)\n",
    "X_test_scaled=pd.DataFrame(X_test_scaled, columns=life.feature.columns)\n",
    "X_val_scaled=pd.DataFrame(X_val_scaled, columns=life.feature.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋, 로더 생성\n",
    "trainDS= Custom_Dataset(featureDF=X_train_scaled, targetDF=life.Y_train.to_frame())\n",
    "testDS= Custom_Dataset(featureDF=X_test_scaled, targetDF=life.Y_test.to_frame())\n",
    "valDS= Custom_Dataset(featureDF=X_val_scaled, targetDF=life.Y_val.to_frame())\n",
    "\n",
    "trainDL=DataLoader(trainDS, batch_size=64)\n",
    "testDL= DataLoader(testDS, batch_size=64)\n",
    "valDL= DataLoader(valDS, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 학습준비\n",
    "\n",
    "- 학습횟수: EPOCH\n",
    "- 배치크기: 64\n",
    "- 위치 지정: DEVICE\n",
    "- 학습률: LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5763"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 학습 모델\n",
    "- 모델 이름: health\n",
    "- 사용 피쳐: 21개\n",
    "- 사용 타겟: 전반적인 건강 정도 (점수로 나타 낼 수 있으면 좋을듯?)\n",
    "- 사용 프레임워크: torch\n",
    "- 사용 알고리즘: DNN\n",
    "- 사용 최적화함수: nn.Adam\n",
    "- 입력층: 25-> 150\n",
    "- 은닉층: 150-> 120, 120-> 100, 100->80\n",
    "- 출력층 80-> 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2054e8a6f30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 설정값\n",
    "EPOCH=100\n",
    "DEVICE= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR= 1\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class make_model(nn.Module):\n",
    "    '''\n",
    "    커스텀 모델을 만드는 함수\n",
    "    model_type= 'reg'|'binary'|'mclf'\n",
    "    은닉층 수= 리스트 수-1\n",
    "    '''\n",
    "    def __init__(self, in_in, out_out, hidden: list) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.in_layer= nn.Linear(in_in, hidden[0])\n",
    "        self.h1_layer=nn.Linear(hidden[0], hidden[1])\n",
    "        self.h2_layer=nn.Linear(hidden[1], hidden[2])\n",
    "        self.h3_layer=nn.Linear(hidden[2], hidden[3])\n",
    "        self.out_layer= nn.Linear(hidden[-1], out_out)\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        \n",
    "        y= self.in_layer(input_data)\n",
    "        y= F.relu(y)\n",
    "\n",
    "        \n",
    "        y=self.h1_layer(y)\n",
    "        y=F.relu(y)\n",
    "        \n",
    "        y=self.h2_layer(y)\n",
    "        y=F.relu(y)\n",
    "\n",
    "        y=self.h3_layer(y)\n",
    "        y=F.relu(y)\n",
    "\n",
    "        y=self.out_layer(y)\n",
    "        \n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "health=make_model(in_in=329, out_out=5, hidden=[150,120,100,80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 인스턴스\n",
    "optimizer= optim.SGD(health.parameters(), lr=LR)\n",
    "\n",
    "# 저장\n",
    "import os\n",
    "# 경로\n",
    "SAVE_PATH= '../models/health/'\n",
    "# 이름\n",
    "SAVE_FILE='model_train_all.pth'\n",
    "\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)       #하위 폴더까지 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 329]) torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "for f, t in trainDL:\n",
    "    # print(f, t)\n",
    "    print(f.shape, t.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_state</th>\n",
       "      <th>fmonth</th>\n",
       "      <th>idate</th>\n",
       "      <th>imonth</th>\n",
       "      <th>iday</th>\n",
       "      <th>iyear</th>\n",
       "      <th>dispcode</th>\n",
       "      <th>seqno</th>\n",
       "      <th>X_psu</th>\n",
       "      <th>ctelenum</th>\n",
       "      <th>...</th>\n",
       "      <th>X_pastae1</th>\n",
       "      <th>X_lmtact1</th>\n",
       "      <th>X_lmtwrk1</th>\n",
       "      <th>X_lmtscl1</th>\n",
       "      <th>X_rfseat2</th>\n",
       "      <th>X_rfseat3</th>\n",
       "      <th>X_flshot6</th>\n",
       "      <th>X_pneumo2</th>\n",
       "      <th>X_aidtst3</th>\n",
       "      <th>X_age80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>491766.000000</td>\n",
       "      <td>491766.000000</td>\n",
       "      <td>4.917640e+05</td>\n",
       "      <td>491766.000000</td>\n",
       "      <td>491763.000000</td>\n",
       "      <td>491761.000000</td>\n",
       "      <td>491766.000000</td>\n",
       "      <td>4.917630e+05</td>\n",
       "      <td>4.917640e+05</td>\n",
       "      <td>491766.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>491766.000000</td>\n",
       "      <td>491766.000000</td>\n",
       "      <td>491766.000000</td>\n",
       "      <td>491766.000000</td>\n",
       "      <td>491766.000000</td>\n",
       "      <td>491766.000000</td>\n",
       "      <td>491766.000000</td>\n",
       "      <td>491766.000000</td>\n",
       "      <td>491766.000000</td>\n",
       "      <td>491755.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.544383</td>\n",
       "      <td>5.441436</td>\n",
       "      <td>6.672334e+06</td>\n",
       "      <td>5.476015</td>\n",
       "      <td>13.749635</td>\n",
       "      <td>2013.011554</td>\n",
       "      <td>0.119077</td>\n",
       "      <td>2.012998e+09</td>\n",
       "      <td>2.012994e+09</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444943</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.620206</td>\n",
       "      <td>0.846531</td>\n",
       "      <td>0.213020</td>\n",
       "      <td>0.283151</td>\n",
       "      <td>1.582192</td>\n",
       "      <td>1.621035</td>\n",
       "      <td>0.490807</td>\n",
       "      <td>54.773696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.451279</td>\n",
       "      <td>3.437338</td>\n",
       "      <td>3.412144e+06</td>\n",
       "      <td>3.464415</td>\n",
       "      <td>8.253900</td>\n",
       "      <td>0.106869</td>\n",
       "      <td>0.323911</td>\n",
       "      <td>4.059589e+06</td>\n",
       "      <td>4.971950e+06</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733290</td>\n",
       "      <td>0.860231</td>\n",
       "      <td>0.929449</td>\n",
       "      <td>1.294700</td>\n",
       "      <td>0.570985</td>\n",
       "      <td>0.601123</td>\n",
       "      <td>0.688566</td>\n",
       "      <td>0.642528</td>\n",
       "      <td>0.686988</td>\n",
       "      <td>17.032090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.022013e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.013002e+09</td>\n",
       "      <td>2.013002e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.022013e+06</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.013005e+09</td>\n",
       "      <td>2.013005e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.001201e+07</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.013008e+09</td>\n",
       "      <td>2.013008e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.231201e+07</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.013034e+09</td>\n",
       "      <td>2.013034e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X_state         fmonth         idate         imonth  \\\n",
       "count  491766.000000  491766.000000  4.917640e+05  491766.000000   \n",
       "mean       27.544383       5.441436  6.672334e+06       5.476015   \n",
       "std        14.451279       3.437338  3.412144e+06       3.464415   \n",
       "min         0.000000       0.000000  1.000000e+00       0.000000   \n",
       "25%        16.000000       3.000000  4.022013e+06       2.000000   \n",
       "50%        26.000000       5.000000  7.022013e+06       5.000000   \n",
       "75%        39.000000       8.000000  1.001201e+07       8.000000   \n",
       "max        54.000000      12.000000  1.231201e+07      12.000000   \n",
       "\n",
       "                iday          iyear       dispcode         seqno  \\\n",
       "count  491763.000000  491761.000000  491766.000000  4.917630e+05   \n",
       "mean       13.749635    2013.011554       0.119077  2.012998e+09   \n",
       "std         8.253900       0.106869       0.323911  4.059589e+06   \n",
       "min         1.000000    2013.000000       0.000000  1.000000e+00   \n",
       "25%         7.000000    2013.000000       0.000000  2.013002e+09   \n",
       "50%        13.000000    2013.000000       0.000000  2.013005e+09   \n",
       "75%        20.000000    2013.000000       0.000000  2.013008e+09   \n",
       "max        31.000000    2014.000000       2.000000  2.013034e+09   \n",
       "\n",
       "              X_psu       ctelenum  ...      X_pastae1      X_lmtact1  \\\n",
       "count  4.917640e+05  491766.000000  ...  491766.000000  491766.000000   \n",
       "mean   2.012994e+09       0.000083  ...       0.444943       0.558601   \n",
       "std    4.971950e+06       0.009131  ...       0.733290       0.860231   \n",
       "min    1.000000e+00       0.000000  ...       0.000000       0.000000   \n",
       "25%    2.013002e+09       0.000000  ...       0.000000       0.000000   \n",
       "50%    2.013005e+09       0.000000  ...       0.000000       0.000000   \n",
       "75%    2.013008e+09       0.000000  ...       1.000000       1.000000   \n",
       "max    2.013034e+09       1.000000  ...       2.000000       3.000000   \n",
       "\n",
       "           X_lmtwrk1      X_lmtscl1      X_rfseat2      X_rfseat3  \\\n",
       "count  491766.000000  491766.000000  491766.000000  491766.000000   \n",
       "mean        0.620206       0.846531       0.213020       0.283151   \n",
       "std         0.929449       1.294700       0.570985       0.601123   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       2.000000       0.000000       0.000000   \n",
       "max         3.000000       4.000000       2.000000       2.000000   \n",
       "\n",
       "           X_flshot6      X_pneumo2      X_aidtst3        X_age80  \n",
       "count  491766.000000  491766.000000  491766.000000  491755.000000  \n",
       "mean        1.582192       1.621035       0.490807      54.773696  \n",
       "std         0.688566       0.642528       0.686988      17.032090  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         1.000000       1.000000       0.000000      42.000000  \n",
       "50%         2.000000       2.000000       0.000000      57.000000  \n",
       "75%         2.000000       2.000000       1.000000      68.000000  \n",
       "max         2.000000       2.000000       2.000000      80.000000  \n",
       "\n",
       "[8 rows x 330 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "life_DF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genhlth\n",
       "3    40199\n",
       "2    37796\n",
       "4    21277\n",
       "1    16695\n",
       "0     6975\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "life.Y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# health=Custom_model(in_in=25, out_out=5, hidden=[150,120,100,80], af=F.relu, model_type='multiclass')\n",
    "# health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhealth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainDL\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainDL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestDL\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalDL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m               \u001b[49m\u001b[43mbreak_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmuticlass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAVE_FILE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAVE_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAVE_PATH\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m               \u001b[49m\u001b[43mnumcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLIMIT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\Desktop\\KDT_06\\Pytorch\\project\\get_train_model.py:31\u001b[0m, in \u001b[0;36mmodel_training\u001b[1;34m(model, trainDL, testDL, optimizer, epoch, LIMIT, break_param, type, optim_type, SAVE_PATH, SAVE_FILE, save_type, numcls)\u001b[0m\n\u001b[0;32m     28\u001b[0m loss_total, score_total\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     29\u001b[0m loss_val_total, score_val_total\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_feature, train_target \u001b[38;5;129;01min\u001b[39;00m trainDL:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# 학습\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     pre_y\u001b[38;5;241m=\u001b[39mmodel(train_feature)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# 손실\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\Desktop\\KDT_06\\Pytorch\\project\\get_dataset.py:16\u001b[0m, in \u001b[0;36mCustom_Dataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m---> 16\u001b[0m     featureTS\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatureDF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     targetTS\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargetDF\u001b[38;5;241m.\u001b[39miloc[index]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m featureTS, targetTS\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_training(health, trainDL=trainDL, testDL=valDL, optimizer=optimizer, epoch=100,\n",
    "               break_param='score', type='muticlass', SAVE_FILE=SAVE_FILE, SAVE_PATH=SAVE_PATH, save_type='all',\n",
    "               numcls=5, LIMIT=15, optim_type='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100\n",
      "Train\n",
      " Loss: nan\n",
      " Score: 0.057223110483500685\n",
      "Val\n",
      " Loss: nan\n",
      " Score: 0.057097746885273706\n",
      "2/100\n",
      "Train\n",
      " Loss: nan\n",
      " Score: 0.057223110483500685\n",
      "Val\n",
      " Loss: nan\n",
      " Score: 0.057097746885273706\n",
      "3/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m loss_total, score_total\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     17\u001b[0m loss_val_total, score_val_total\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_feature, train_target \u001b[38;5;129;01min\u001b[39;00m trainDL:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# 학습\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     pre_y\u001b[38;5;241m=\u001b[39mmodel(train_feature)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# 손실\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\Desktop\\KDT_06\\Pytorch\\project\\get_dataset.py:17\u001b[0m, in \u001b[0;36mCustom_Dataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m     16\u001b[0m     featureTS\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatureDF\u001b[38;5;241m.\u001b[39miloc[index]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m---> 17\u001b[0m     targetTS\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargetDF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m featureTS, targetTS\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=health\n",
    "trainDL=trainDL; testDL=valDL;  optimizer=optimizer;  epoch=100\n",
    "break_param='score'; mtype='muticlass'; SAVE_FILE=SAVE_FILE; SAVE_PATH=SAVE_PATH; save_type='all'\n",
    "numcls=5; LIMIT=15; optim_type='score'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scheduler= lr_scheduler.ReduceLROnPlateau(optimizer, patience=LIMIT, mode='max')\n",
    "EPOCH=100\n",
    "# 손실, 평가값 저장\n",
    "LOSS_HISTORY, SCORE_HISTORY= [[],[]], [[],[]]\n",
    "for ep in range(EPOCH):\n",
    "    print(f'{ep+1}/{EPOCH}')\n",
    "    model.train()\n",
    "    loss_total, score_total= 0,0\n",
    "    loss_val_total, score_val_total=0,0\n",
    "\n",
    "    for train_feature, train_target in trainDL:\n",
    "        # 학습\n",
    "        pre_y=model(train_feature)\n",
    "        # 손실\n",
    "        if mtype=='reg':\n",
    "            Lossfunc=MeanSquaredError()\n",
    "            Scorefunc=R2Score()\n",
    "        elif mtype=='binary':\n",
    "            Lossfunc= nn.BCELoss()\n",
    "            Scorefunc=F1Score(task='binary', num_classes=numcls)\n",
    "        elif mtype=='muticlass':\n",
    "            Lossfunc=nn.CrossEntropyLoss()\n",
    "            Scorefunc=Accuracy(task='MULTICLASS',num_classes=5)\n",
    "\n",
    "        loss= Lossfunc(pre_y, train_target.reshape(-1).long() if mtype=='muticlass' else train_target)\n",
    "        loss_total+=loss.item()\n",
    "\n",
    "        # 평가\n",
    "        score= Scorefunc(pre_y, train_target.reshape(-1) if mtype=='muticlass' else train_target if mtype=='reg' else train_target)\n",
    "        score_total+=score.item()\n",
    "        # 최적화\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 검증\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_feature, val_target in testDL:\n",
    "            # 학습\n",
    "            pre_val= model(val_feature)\n",
    "\n",
    "            # 손실\n",
    "            loss= Lossfunc(pre_val, val_target.reshape(-1).long() if mtype=='muticlass' else val_target if mtype=='reg' else val_target)\n",
    "            loss_val_total+=loss.item()\n",
    "\n",
    "            # 평가\n",
    "            score= Scorefunc(pre_val, val_target.reshape(-1) if mtype=='muticlass' else val_target)\n",
    "            score_val_total+=score.item()\n",
    "\n",
    "    \n",
    "    # 저장\n",
    "    LOSS_HISTORY[0].append(loss_total/len(trainDL))\n",
    "    SCORE_HISTORY[0].append(score_total/len(trainDL))\n",
    "    print(f'Train\\n Loss: {loss_total/len(trainDL)}\\n Score: {score_total/len(trainDL)}')\n",
    "\n",
    "    LOSS_HISTORY[1].append(loss_val_total/len(testDL))\n",
    "    SCORE_HISTORY[1].append(score_val_total/len(testDL))\n",
    "    print(f'Val\\n Loss: {loss_val_total/len(testDL)}\\n Score: {score_val_total/len(testDL)}')\n",
    "\n",
    "    # 성능이 좋은 학습 가중치 저장\n",
    "    if save_type:\n",
    "        if save_type=='all':\n",
    "            save_type= model\n",
    "        elif save_type=='param':\n",
    "            save_type=model.state_dict()\n",
    "        if len(SCORE_HISTORY[1]) == 1: \n",
    "        #첫번째는 무조건 저장\n",
    "            torch.save(save_type, SAVE_PATH+SAVE_FILE)  \n",
    "            \n",
    "        else:\n",
    "            if SCORE_HISTORY[1][-1]> max(SCORE_HISTORY[1][:-1]): # 자신을 제외한 최대점수값과 비교\n",
    "                torch.save(save_type, SAVE_PATH+SAVE_FILE) \n",
    "                    \n",
    "    else: pass\n",
    "\n",
    "    \n",
    "    # 학습 진행 모니터링 (검증 데이터 개선이 되지 않았을때 누적 ->  평가, 손실 중 지표 하나 선택)\n",
    "    # 최적화 스케쥴러 인스턴스 업데이트\n",
    "    scheduler.step(score_val_total/len(testDL))\n",
    "    # print(f'scheduler.num_bad_epochs: {scheduler.num_bad_epochs}', end=' ') #보여주기용\n",
    "    # print(f'scheduler.patience: {scheduler.patience}')\n",
    "    # 손실 감소 (또는 성능 개선)이 안되는 경우 조기종료\n",
    "    if scheduler.num_bad_epochs== scheduler.patience:\n",
    "        print(f'{scheduler.patience} EPOCH 성능 개선이 없어서 조기종료함')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 926. MiB for an array with shape (329, 368824) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlife\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\pandas\\core\\frame.py:10054\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  10052\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  10053\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 10054\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  10056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  10057\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\pandas\\core\\frame.py:1838\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1837\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1838\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1840\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1732\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1730\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1732\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32mc:\\Users\\KDP-25\\anaconda3\\envs\\PYTORCH_38\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1768\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_dtype_equal(dtype, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1766\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1768\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1770\u001b[0m itemmask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;66;03m# much more performant than using to_numpy below\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 926. MiB for an array with shape (329, 368824) and data type float64"
     ]
    }
   ],
   "source": [
    "life.X_train.corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
