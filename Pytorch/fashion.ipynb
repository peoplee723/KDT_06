{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST & IRIS 모델 구현\n",
    "- Fashion MNIST 모델 \n",
    "    - 옷 판별 모델 구현\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 구현 과정\n",
    "    - 데이터 전처리 (결측치, 이상치, 중복치 처리 등등)\n",
    "    - 학습 모델 설계 (모델 인스턴스 생성 + forward 메서드)\n",
    "    - 데이터셋 모델 설계 (모델 인스턴스 생성 + 배치수 만큼 텐서화 진행)\n",
    "    - 데이터 분리, 인코딩, 스케일링\n",
    "    - 최적화, 손실함수 인스턴스 정하기\n",
    "    - 만든 모델을 바탕으로 학습 진행  \n",
    "        (데이터 로딩 -> 학습 -> 손실 -> 평가 -> 최적화-> 검증 및 결과 저장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve  #(데이터 불러오는 모듈)\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from torchmetrics import F1Score\n",
    "from torchmetrics.classification import MulticlassF1Score, MulticlassConfusionMatrix\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "from func import Torch_preccesing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 데이터 전처리 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 고정\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 텐서 저장 및 실행 위치 설정\n",
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "# TEST_URL  = 'https://media.githubusercontent.com/media/fpleoni/fashion_mnist/master/fashion-mnist_test.csv'\n",
    "# TRAIN_URL = 'https://media.githubusercontent.com/media/fpleoni/fashion_mnist/master/fashion-mnist_train.csv'\n",
    "\n",
    "TRAIN_FILE = './data/fashion-mnist_train.csv'\n",
    "TEST_FILE  = './data/fashion-mnist_test.csv'\n",
    "# # 데이터 파일로 저장\n",
    "# urlretrieve(TRAIN_URL, TRAIN_FILE)   #url에 있는 파일을 지정 경로에 저장\n",
    "# urlretrieve(TEST_URL, TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF= pd.read_csv(TRAIN_FILE)\n",
    "testDF= pd.read_csv(TEST_FILE)\n",
    "# 사진 데이터 이므로 결측치, 이상치, 중복치 처리 X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.columns[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 9, 6, 0, 3, 4, 5, 8, 7, 1], dtype=int64),\n",
       " Index(['pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6', 'pixel7',\n",
       "        'pixel8', 'pixel9', 'pixel10',\n",
       "        ...\n",
       "        'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780',\n",
       "        'pixel781', 'pixel782', 'pixel783', 'pixel784'],\n",
       "       dtype='object', length=784))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피쳐/타겟 분리\n",
    "FashionDF=Torch_preccesing(trainDF)\n",
    "\n",
    "FashionDF.feature= trainDF[trainDF.columns[1:]]\n",
    "FashionDF.target= trainDF[trainDF.columns[:1]]\n",
    "\n",
    "FashionDF.target['label'].unique(), FashionDF.feature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피쳐: pixel 1 ~ 784  (784 컬럼)\n",
    "# 타겟: label (0~9 10가지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "FashionDF.X_test=testDF[testDF.columns[1:]]\n",
    "FashionDF.Y_test=testDF[testDF.columns[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중분류 -> 라벨은 onehot_encoding\n",
    "# 훈련\n",
    "# target_enc=FashionDF.encoding(OneHotEncoder(), FashionDF.target)\n",
    "# target_enc.toarray()\n",
    "# FashionDF.target=pd.DataFrame(target_enc, columns=[f'class_{i}' for i in range(FashionDF.target.shape[0])])\n",
    "# # 테스트\n",
    "# test_enc= FashionDF.encoding(OneHotEncoder(), FashionDF.Y_test)\n",
    "# test_enc= test_enc.toarray()\n",
    "# FashionDF.Y_test=pd.DataFrame(test_enc, columns=[f'class_{i}' for i in range(FashionDF.Y_test.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (45000, 784),(45000, 1)\n",
      "test: (15000, 784),(15000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 훈련, 검증 데이터 분리 (테스트는 별도로 존재)\n",
    "\n",
    "FashionDF.X_train, FashionDF.X_val, FashionDF.Y_train, FashionDF.Y_val= FashionDF.split(val=False,\n",
    "                                                                                        testsize=.25,\n",
    "                                                                                        random_state=916,\n",
    "                                                                                        get_data=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled: (45000, 784),2\n",
      "X_test_scaled: (10000, 784),2\n",
      "X_val_scaled: (15000, 784),2\n"
     ]
    }
   ],
   "source": [
    "# 스케일링을 해야할까?\n",
    "# 1. 스케일링 O -> MinMaxScaler()\n",
    "FashionDF.get_scaled(MinMaxScaler(), val=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 데이터 설계\n",
    "- 클래스 목적: Fashion 데이터 학습 및 추론\n",
    "- 클래스 이름: FashionMClf\n",
    "- 부모 클래스: nn.Module()\n",
    "- 매개변수: 입출력 개수, AF, 마지막 출력 AF, 은닉층의 수\n",
    "\n",
    "- 구조 설정\n",
    "    - 입력층: 784 -> 20, AF= Relu\n",
    "    - 은닉층: 20 -> 30, AF= Relu, 3층\n",
    "    - 출력층: 30 -> 라벨 컬럼 수(10), softMAX인데, Cross Entropy 사용시 필요 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_classification_model(nn.Module):\n",
    "    '''\n",
    "    은닉층 수= 리스트 수-1\n",
    "    '''\n",
    "    def __init__(self, in_in, out_out, hidden: list) -> None:\n",
    "        super().__init__()\n",
    "        self.in_layer= nn.Linear(in_in, hidden[0])\n",
    "        self.h_layers=nn.ModuleList()\n",
    "        for h in range(len(hidden)-1):\n",
    "            self.h_layers.append(nn.Linear(hidden[h], hidden[h+1]))\n",
    "        self.out_layer= nn.Linear(hidden[-1], out_out)\n",
    "    \n",
    "    def forward(self, input_data, out_AF=None):\n",
    "        y= self.in_layer(input_data)\n",
    "        y= F.relu(y)\n",
    "\n",
    "        for layer in self.h_layers:\n",
    "            y=layer(y)\n",
    "            y=F.relu(y)\n",
    "        \n",
    "        if out_AF:\n",
    "            y= out_AF(self.out_layer(y))\n",
    "        else:\n",
    "            y=self.out_layer(y)\n",
    "        return y\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_classification_model(\n",
      "  (in_layer): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (h_layers): ModuleList(\n",
      "    (0): Linear(in_features=100, out_features=80, bias=True)\n",
      "    (1): Linear(in_features=80, out_features=60, bias=True)\n",
      "    (2): Linear(in_features=60, out_features=40, bias=True)\n",
      "    (3): Linear(in_features=40, out_features=20, bias=True)\n",
      "  )\n",
      "  (out_layer): Linear(in_features=20, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "get_classification_model                 [60000, 10]               --\n",
       "├─Linear: 1-1                            [60000, 100]              78,500\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─Linear: 2-1                       [60000, 80]               8,080\n",
       "│    └─Linear: 2-2                       [60000, 60]               4,860\n",
       "│    └─Linear: 2-3                       [60000, 40]               2,440\n",
       "│    └─Linear: 2-4                       [60000, 20]               820\n",
       "├─Linear: 1-3                            [60000, 10]               210\n",
       "==========================================================================================\n",
       "Total params: 94,910\n",
       "Trainable params: 94,910\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 5.69\n",
       "==========================================================================================\n",
       "Input size (MB): 188.16\n",
       "Forward/backward pass size (MB): 148.80\n",
       "Params size (MB): 0.38\n",
       "Estimated Total Size (MB): 337.34\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 테스트\n",
    "a=[100,80,60,40,20]\n",
    "model= get_classification_model(in_in=784, out_out=10, hidden=a)\n",
    "print(model)\n",
    "summary(model, input_size=(60000, 784)) #행과 열"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 클래스 설계\n",
    "- 피쳐: 784개\n",
    "- 타겟: 10개(인코딩)\n",
    "- 클래스 이름: FashionDataset\n",
    "- 부모 클래스: untils.data.Dataset\n",
    "- 속성/필드: feature, target, nrows, n_features\n",
    "- 필수 메서드 오버라이딩\n",
    "    - init\n",
    "    - len\n",
    "    - get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, featureDF, targetDF) -> None:\n",
    "        super().__init__()\n",
    "        self.featureDF= featureDF\n",
    "        self.targetDF= targetDF\n",
    "        self.n_rows= featureDF.shape[0]\n",
    "        self.n_features= featureDF.shape[1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        featureTS= torch.FloatTensor(self.featureDF.iloc[index].values).to(DEVICE)\n",
    "        targetTS= torch.FloatTensor(self.targetDF.iloc[index].values).to(DEVICE)\n",
    "        return featureTS, targetTS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000\n",
      "torch.Size([32, 784]) torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "feature= FashionDF.X_train_scaled\n",
    "target= FashionDF.Y_train\n",
    "testDS=CustomDataset(pd.DataFrame(feature), pd.DataFrame(target))\n",
    "print(testDS.n_rows)\n",
    "testDL=DataLoader(testDS, batch_size=32)\n",
    "for f, t in testDL:\n",
    "    print(f.shape, t.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 준비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정값\n",
    "EPOCH= 100\n",
    "BATCH_SIZE=32\n",
    "LR=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552      7\n",
       "50513    0\n",
       "27703    9\n",
       "37981    2\n",
       "50552    8\n",
       "        ..\n",
       "8202     4\n",
       "52576    3\n",
       "33372    5\n",
       "11477    4\n",
       "36076    2\n",
       "Name: label, Length: 45000, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FashionDF.Y_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 라벨 인코딩\n",
    "# scikit-learn -> 라벨은 무조건 1차원 => DF인 경우 values로 numpy변경 후 ravel()통해 1차원으로 변환\n",
    "                                                                    # 넘파이 함수\n",
    "# enc_model=LabelEncoder()\n",
    "# enc_model.fit(FashionDF.Y_train.values.ravel())\n",
    "# enc_model.transform(FashionDF.Y_train.values.ravel())\n",
    "# enc_model.transform(FashionDF.Y_test.values.ravel())\n",
    "# enc_model.transform(FashionDF.Y_val.values.ravel())\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "trainDS= CustomDataset(pd.DataFrame(FashionDF.X_train_scaled), pd.DataFrame(FashionDF.Y_train))\n",
    "testDS= CustomDataset(pd.DataFrame(FashionDF.X_test_scaled), pd.DataFrame(FashionDF.Y_test))\n",
    "valDS= CustomDataset(pd.DataFrame(FashionDF.X_val_scaled), pd.DataFrame(FashionDF.Y_val))\n",
    "trainDL= DataLoader(trainDS, batch_size=BATCH_SIZE)\n",
    "testDL= DataLoader(testDS, batch_size=BATCH_SIZE)\n",
    "valDL= DataLoader(valDS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 784])\n"
     ]
    }
   ],
   "source": [
    "# DL 테스트\n",
    "for f, t in trainDL:\n",
    "    print(f.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 인스턴스 사용할 최적화 모델 이름(모델 파라미터, 단계)\n",
    "optimizer= optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 손실함수 인스턴스 -> 다중분류\n",
    "Loss= nn.CrossEntropyLoss()\n",
    "\n",
    "# 학습 모델\n",
    "h_layer=[200,150,100]\n",
    "model= get_classification_model(in_in=784, out_out=10, hidden=h_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "2/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "3/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "4/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "5/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "6/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "7/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "8/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "9/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "10/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "11/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "12/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "13/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "14/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "15/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "16/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "17/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "18/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "19/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "20/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "21/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "22/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "23/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "24/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "25/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "26/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "27/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "28/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "29/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "30/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "31/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "32/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "33/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "34/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "35/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "36/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "37/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "38/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "39/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "40/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "41/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "42/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "43/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "44/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "45/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "46/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "47/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "48/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "49/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "50/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "51/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "52/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "53/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "54/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "55/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "56/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "57/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "58/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "59/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "60/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "61/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "62/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "63/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "64/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "65/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "66/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "67/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "68/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "69/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "70/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "71/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "72/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "73/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "74/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "75/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "76/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "77/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "78/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "79/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "80/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "81/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "82/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "83/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "84/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "85/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "86/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "87/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "88/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "89/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "90/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "91/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "92/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "93/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "94/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "95/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "96/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "97/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "98/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "99/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n",
      "100/100\n",
      "Train\n",
      " Loss: 101.30159759521484\n",
      " Score: 0.8095508217811584\n",
      "Val\n",
      " Loss: 33.75965118408203\n",
      " Score: 0.2703002691268921\n"
     ]
    }
   ],
   "source": [
    "# 손실, 평가값 저장\n",
    "LOSS_HISTORY, SCORE_HISTORY= [[],[]], [[],[]]\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCH):\n",
    "    print(f'{epoch+1}/{EPOCH}')\n",
    "\n",
    "    loss_total, score_total= 0,0\n",
    "    loss_val_total, score_val_total=0,0\n",
    "    for feature, target in trainDL:\n",
    "        # 학습\n",
    "        pre_y=model(feature)\n",
    "\n",
    "        # 손실\n",
    "        loss= Loss(pre_y, target.reshape(-1).long())\n",
    "        loss_total+=loss\n",
    "\n",
    "        # 평가\n",
    "        target=target.reshape(-1)\n",
    "        score_total+= MulticlassF1Score(num_classes=10)(pre_y, target)\n",
    "        # 최적화\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 검증\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for feature, target in valDL:\n",
    "            # 학습\n",
    "            pre_val= model(feature)\n",
    "\n",
    "            # 손실\n",
    "            loss= Loss(pre_val, target.reshape(-1).long())\n",
    "            loss_val_total+=loss\n",
    "            # 평가\n",
    "            score= MulticlassF1Score(num_classes=10)(pre_val, target.reshape(-1))\n",
    "            score_val_total+=score\n",
    "    # 테스트\n",
    "\n",
    "    \n",
    "    # 저장\n",
    "    LOSS_HISTORY[0].append(loss_total/BATCH_SIZE)\n",
    "    SCORE_HISTORY[0].append(score_total/BATCH_SIZE)\n",
    "    print(f'Train\\n Loss: {loss_total/BATCH_SIZE}\\n Score: {score_total/BATCH_SIZE}')\n",
    "\n",
    "    LOSS_HISTORY[1].append(loss_val_total/BATCH_SIZE)\n",
    "    SCORE_HISTORY[1].append(score_val_total/BATCH_SIZE)\n",
    "    print(f'Val\\n Loss: {loss_val_total/BATCH_SIZE}\\n Score: {score_val_total/BATCH_SIZE}')\n",
    "\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
