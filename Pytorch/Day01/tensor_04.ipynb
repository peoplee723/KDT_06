{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor 변환\n",
    "- 공유(sharing): .as_tensor(), .from_numpy()\n",
    "- 복사(copy): .tensor(), .Tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int8, 1, torch.Size([9]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python-> Tensor\n",
    "# [1] list\n",
    "# .as_tensor\n",
    "data= list(range(1,10))\n",
    "\n",
    "dataTS=torch.as_tensor(data, dtype=torch.int8)\n",
    "dataTS.dtype, dataTS.ndim, dataTS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] Numpy ndarray\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] (3,) int32 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 77,   2, 100], dtype=torch.int32), array([ 77,   2, 100]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .as_tensor()\n",
    "\n",
    "# Converts data into a tensor, sharing data and preserving autograd history if possible.\n",
    "# 데이터를 공유함 (기본)\n",
    "\n",
    "# but, if data is a tensor with a different dtype or device \n",
    "#                                               then it's copied as if using data.to(dtype=dtype, device=device).\n",
    "# dtype or dvice가 다를 경우에는 카피\n",
    "arr1= np.array([1,2,3])\n",
    "print(arr1, arr1.shape, arr1.dtype, arr1.ndim)\n",
    "arrTS= torch.as_tensor(arr1)\n",
    "arr1[0]=77\n",
    "arrTS[2]=100\n",
    "arrTS, arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 저장 메모리: <memory at 0x0000020A13B2A040>\n",
      "원소/요소 개수: 6\n",
      "원소/요소 1개 크기: <memory at 0x0000020A13B2A040>\n",
      "타입: float32\n",
      "방향: (12, 4)\n"
     ]
    }
   ],
   "source": [
    "#from_numpy\n",
    "arr1=np.array([[5,7,9], [1,2,3]], dtype=np.float32) \n",
    "\n",
    "print(f'데이터 저장 메모리: {arr1.data}')\n",
    "print(f'원소/요소 개수: {arr1.size}')\n",
    "print(f'원소/요소 1개 크기: {arr1.data}')\n",
    "print(f'타입: {arr1.dtype}')\n",
    "print(f'방향: {arr1.strides}') #-> 개당 4bytes, 다음 행으로 넘어가는데 12bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 7., 9.],\n",
       "        [1., 2., 3.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrTS=torch.from_numpy(arr1)\n",
    "# The returned tensor and ndarray share the same memory\n",
    "# 새로운 텐서 생성(복사)\n",
    "arrTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
