{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 퍼셉트론 개념에 대해 설명하세요  \n",
    "퍼셉트론은 인간이 감각을 느끼는 원리를 컴퓨터에 적용하기 위해 고안해낸 일종의 인공신경망이다. 인간은 수용세포를 통해 감각을 입력받고 뉴런을 통해 감각의 정도를 측정하여 반응한다. 이러한 뉴런을 모방하여 퍼셉트론은 입력받은 데이터를 퍼셉트론의 가상의 뉴런을 통해 데이터를 측정하여 분류나, 회귀 등을 수행할 수 있게 해 준다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 퍼셉트론 기본 동작 원리 및 수식을 도식화와 함께 작성해주세요\n",
    "- 퍼셉트론에서 4개의 피쳐 입력받아 각 피쳐의 가중치에와 하나의 절편에 대한 식이 생성된다 (w1x1+ w2x2+ w3x3 + w4x4 + b)\n",
    "\n",
    "- 생성된 식이 활성화 함수를 통해 분류, 회귀, 다중회귀에 따라 식 또는 확률값 이 도출된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 활성화 함수의 역할을 설명하세요.   \n",
    "활성화 함수는 퍼셉트론으로 인해 생성된 가중치 및 절편식을 통해 결과를 도출해준다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 대표적인 활성화함수에 대해 설명하세요   \n",
    "- sigmoid: 0 또는 1 도출\n",
    "- relu: 0 이상 y이하 도출 (0 미만인 수를 모두 0으로 처리)\n",
    "- sotfmax: 0이상 1이하 도출 (확률값)\n",
    "- leacky relu: 0이상 y이하 도출 (0 미만인 수를 0에 가깝게 처리)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 경사하강법의 개념 및 대표적인 경사하강법 알고리즘에 대해 간략히 설명하세요\n",
    "- Adam: 오른쪽에서 왼쪽으로 이동하면서 최적점을 찾는 알고리즘\n",
    "- : 왼쪽에서 오른쪽으로 이동하면서 최적점을 찾는 알고리즘\n",
    "- : 랜덤한 구간을 이동하면서 최적점을 찾는 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] 회귀 모델 구현을 간략하게 코드 작성(피쳐 3개)   \n",
    "\n",
    "- 학습 코드 생성 (순전파)\n",
    "y= nn.linear(feature)  \n",
    "y= F.relu(y)  \n",
    "- 손실, 평가 측정  \n",
    "loss=loss_func(y, target)  \n",
    "score= r2score(y,target)  \n",
    "- 최적화 (역전파)  \n",
    "optim.?   \n",
    "loss.backward()  \n",
    "optim.step()  \n",
    "- .... 에포크 만큼 반복 및 최적의 모델 선정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7] 이진분류 모델 구현을 간략하게 코드 작성 (피쳐 5개, 클래스 2개, 층 4개)\n",
    "- 훈련 모델 클래스 생성     \n",
    "class custom(Model):\n",
    "    def __init__(self, in=5, h1=3, h2=3, out=1):\n",
    "    sup.__init__()\n",
    "    self.in=nn.linear(5,3)\n",
    "    self.h1=nn.linear(3,3)\n",
    "    self.h2=nn.linear(3,3)\n",
    "    self.out=nn.linear(3,1)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        y= self.in(input)\n",
    "        y=F.relu(y)\n",
    "        y= self.h1(y)\n",
    "        y= F.relu(y)\n",
    "        y= self.h2(y)\n",
    "        y= F.relu(y)\n",
    "        y=self.out(y)\n",
    "        y= sigmoid(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "[8] 다중분류 모델 구현을 간략하게 코드 작성\n",
    "h_list=[10,20,30]  \n",
    "class custom2:\n",
    "    def __init__(self, in=5,out=8, h_list: list):\n",
    "    sup.__init__()\n",
    "    self.in=nn.linear(in,h1)\n",
    "    self.h_lists=torch.modul_list()\n",
    "    for h in range(len(h_list)-1):\n",
    "        self.h_lists.append(nn.Linear(h, h+1))\n",
    "    self.h3=nn.linear(h_list[-1],h_out)\n",
    "    self.out=nn.linear(h_out, out)\n",
    "\n",
    "    def forward(self, input):\n",
    "        y=self.in(input)\n",
    "        y=F.relu(y)\n",
    "        for layer in h_lists:\n",
    "            y=layer(y)\n",
    "            y=F.relu(y)\n",
    "        y=self.out(y)\n",
    "        return y (손실에서 자동 sotfmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "[9] 기울기 소실 개념 및 해결 방법을 설명하세요  \n",
    "기울기 소실이란 역전파에서 학습을 반영할 때 나타나는 현상이다. 역전파에서 최적화를 진행할 때 \n",
    "미분을 통해 학습을 반영하는데, 층이 많을수록 미분을 많이 시행하면 결국 기울기가 0으로 없어지는\n",
    "문제가 발생 할 수 있다. 이를 해결하기 위해서는 층 수를 조절하거나 최적화 함수를 바꾸는 방법 등이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "[10] 파이토치의 모델 동작 모드에 대해 관련 함수도 함께 설명하시오  \n",
    "- model.train()  \n",
    "훈련 모드로 훈련 관련 통계나 수치가 작동되도록 해준다.\n",
    "- model.eval()  \n",
    "테스트 및 검증 모드로 훈련 관련 통계가 수치가 동작하지 않도록 하여 메모리를 아끼게 해준다\n",
    "- torch.no_grand()    \n",
    "테스트 및 검증시 학습한 데이터를 모델에 반영하지 않도록 막는 함수이다다\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
